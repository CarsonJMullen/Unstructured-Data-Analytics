{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b1dc68",
   "metadata": {},
   "source": [
    "**Members:** Ethan Wong, Timmy Ren, Mason Shu, Medha Nalamada, Carson Mullen, Bethel Kim\n",
    "\n",
    "**Morning Cohort**: 11 AM - 1 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7563a96",
   "metadata": {},
   "source": [
    "**Current Tasks Remaining:**\n",
    "\n",
    "1. Perform Active/Passive/Topic Voice Analysis --> Timmy\n",
    "2. Use ChatGPT to generate sentiment for actors in a given category (-100 to 100) --> Ethan\n",
    "3. Implement Bias Score Metric --> Timmy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb917e6",
   "metadata": {},
   "source": [
    "# Install and Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4f7e67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "#!pip install eventregistry\n",
    "!python -m spacy download en_core_web_lg\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#from eventregistry import *\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import spacy # type: ignore\n",
    "from spacy.matcher import Matcher\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1928fbe1",
   "metadata": {},
   "source": [
    "# Scraping Articles with Event Registry API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcaf719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated DataFrames: ['Election_df', 'Gaza_df', 'FEMA_df', 'Abortion_df', 'Inflation_df', 'Unemployment_df', 'Dockworkers_df', 'Immigration_df']\n"
     ]
    }
   ],
   "source": [
    "# Load the API key from the JSON file\n",
    "with open(\"config.json\", \"r\") as file:\n",
    "    config = json.load(file)\n",
    "api_key = config[\"api_key\"]\n",
    "\n",
    "# Initialize EventRegistry with the API key\n",
    "er = EventRegistry(apiKey=api_key, allowUseOfArchive=False)\n",
    "\n",
    "# Define topics to search for\n",
    "#topics = [\n",
    "    #\"Donald Trump\", \"Kamala Harris\", \"Israel\", \"Palestine\", \"Palestinians\", \"Hamas\", \"FEMA\", \"Abortion\",\n",
    "    #\"Inflation\", \"Unemployment\", \"Economy\", \"Dockworkers\", \"ILA Port\", \"Immigration\"\n",
    "#]\n",
    "\n",
    "topics = [\"Election\", \"Gaza\", \"FEMA\", \"Abortion\", \"Inflation\", \"Unemployment\", \"Dockworkers\", \"Immigration\"]\n",
    "\n",
    "# Define sources to search for and get their URIs\n",
    "source_names = [\"NPR\", \"MSNBC\", \"AP News\", \"FOX\", \"Forbes\"]\n",
    "source_uris = {source: er.getNewsSourceUri(source) for source in source_names}\n",
    "\n",
    "# List to store the names of all generated DataFrames\n",
    "dataframe_names = []\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in topics:\n",
    "    # Get the URI for the concept\n",
    "    concept_uri = er.getConceptUri(topic)\n",
    "    \n",
    "    # List to hold all articles' data for the current topic (across all sources)\n",
    "    articles_data = []\n",
    "    \n",
    "    # Loop through each source individually\n",
    "    for source_name, source_uri in source_uris.items():\n",
    "        # Define the query for each topic and source\n",
    "        q = QueryArticlesIter(\n",
    "            conceptUri=concept_uri,\n",
    "            sourceUri=source_uri,\n",
    "            sourceLocationUri=er.getLocationUri(\"United States\"),  # Only US sources\n",
    "        )\n",
    "\n",
    "        # Fetch and accumulate up to 500 articles for the current topic from this source\n",
    "        for art in q.execQuery(er, sortBy=\"date\", maxItems=500):\n",
    "            articles_data.append({\n",
    "                \"title\": art.get(\"title\"),\n",
    "                \"source\": art.get(\"source\", {}).get(\"title\"),\n",
    "                \"author\": art.get(\"author\"),\n",
    "                \"url\": art.get(\"url\"),\n",
    "                \"publishedAt\": art.get(\"dateTime\"),\n",
    "                \"content\": art.get(\"body\")\n",
    "            })\n",
    "\n",
    "    # Create a single DataFrame for the current topic with articles from all sources\n",
    "    articles_df = pd.DataFrame(articles_data)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_name = f\"{topic.replace(' ', '_')}_articles.csv\"\n",
    "    articles_df.to_csv(file_name, index=False)\n",
    "\n",
    "    # Dynamically set the DataFrame name based on the topic, replacing spaces with underscores\n",
    "    df_name = f\"{topic.replace(' ', '_')}_df\"\n",
    "    globals()[df_name] = articles_df\n",
    "\n",
    "    # Append the DataFrame name to the list\n",
    "    dataframe_names.append(df_name)\n",
    "\n",
    "# Print the list of all generated DataFrame names\n",
    "print(\"Generated DataFrames:\", dataframe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1055b4b",
   "metadata": {},
   "source": [
    "# Cleaning Dataframes and Running Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f3f3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in CSVs dynamically\n",
    "\n",
    "topics = [\"Election\", \"Gaza\", \"FEMA\", \"Abortion\", \"Inflation\", \"Unemployment\", \"Dockworkers\", \"Immigration\"]\n",
    "\n",
    "# Dictionary to hold the DataFrames after reading them from CSV\n",
    "dataframes = {}\n",
    "\n",
    "# Loop to read each CSV and store the DataFrame in the dictionary\n",
    "for topic in topics:\n",
    "    # Replace spaces with underscores to match your file naming convention\n",
    "    file_name = f\"{topic.replace(' ', '_')}_articles.csv\"\n",
    "    try:\n",
    "        dataframes[topic.replace(' ', '_')] = pd.read_csv(file_name)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")  # If a file is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46875a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframes\n",
    "def count_sentences(text):\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    return len([s for s in sentences if s.strip()])\n",
    "\n",
    "def clean_df(df):\n",
    "    df = df.drop_duplicates().copy()\n",
    "    df.loc[:, 'content'] = df['content'].str.replace(\n",
    "        \"By entering your email and pushing continue, you are agreeing to Fox News\\' Terms of Use and Privacy Policy, which includes our Notice of Financial Incentive.\\n\\n\", \n",
    "        \"\", \n",
    "        regex=False\n",
    "    )\n",
    "    df.loc[:, 'num_sentences'] = df['content'].apply(count_sentences)\n",
    "    return df\n",
    "\n",
    "# Apply clean_df to each DataFrame in the dictionary\n",
    "cleaned_dataframes = {key: clean_df(df) for key, df in dataframes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2127e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic: Election\n",
      "Top entities for Election:\n",
      " Trump           7078\n",
      "Harris          4119\n",
      "Biden           1937\n",
      "Vance            963\n",
      "GOP              826\n",
      "Georgia          787\n",
      "Congress         659\n",
      "Walz             654\n",
      "Pennsylvania     638\n",
      "Israel           618\n",
      "Name: count, dtype: int64\n",
      "Processing topic: Gaza\n",
      "Top entities for Gaza:\n",
      " Israel       3739\n",
      "Hezbollah    1708\n",
      "Gaza         1339\n",
      "Lebanon      1300\n",
      "Hamas        1143\n",
      "Iran          875\n",
      "Biden         510\n",
      "Harris        459\n",
      "Trump         411\n",
      "Beirut        288\n",
      "Name: count, dtype: int64\n",
      "Processing topic: FEMA\n",
      "Top entities for FEMA:\n",
      " Trump         1237\n",
      "Harris        1180\n",
      "Georgia        357\n",
      "Biden          355\n",
      "California     294\n",
      "Combs          293\n",
      "Texas          282\n",
      "Israel         274\n",
      "America        253\n",
      "Florida        234\n",
      "Name: count, dtype: int64\n",
      "Processing topic: Abortion\n",
      "Top entities for Abortion:\n",
      " Trump       2572\n",
      "Harris      1889\n",
      "Vance        610\n",
      "Biden        537\n",
      "Walz         387\n",
      "GOP          315\n",
      "Georgia      295\n",
      "Senate       258\n",
      "Robinson     215\n",
      "Florida      210\n",
      "Name: count, dtype: int64\n",
      "Processing topic: Inflation\n",
      "Top entities for Inflation:\n",
      " Trump       1648\n",
      "Harris      1316\n",
      "Fed          965\n",
      "Biden        553\n",
      "China        291\n",
      "Forbes       279\n",
      "America      196\n",
      "Israel       190\n",
      "Vance        181\n",
      "Michigan     175\n",
      "Name: count, dtype: int64\n",
      "Processing topic: Unemployment\n",
      "Top entities for Unemployment:\n",
      " Fed       473\n",
      "Trump     221\n",
      "Harris    182\n",
      "China     111\n",
      "FOMC       98\n",
      "Biden      95\n",
      "Forbes     88\n",
      "Israel     60\n",
      "Gaza       51\n",
      "Powell     41\n",
      "Name: count, dtype: int64\n",
      "Processing topic: Dockworkers\n",
      "Top entities for Dockworkers:\n",
      " Trump        3669\n",
      "Harris       1753\n",
      "Israel       1122\n",
      "Biden         876\n",
      "Florida       758\n",
      "Vance         586\n",
      "GOP           549\n",
      "Hezbollah     474\n",
      "Lebanon       453\n",
      "NFL           426\n",
      "Name: count, dtype: int64\n",
      "Processing topic: Immigration\n",
      "Top entities for Immigration:\n",
      " Trump          3669\n",
      "Harris         2295\n",
      "Biden           963\n",
      "Vance           778\n",
      "Springfield     672\n",
      "Ohio            595\n",
      "GOP             367\n",
      "Walz            356\n",
      "America         313\n",
      "Congress        286\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Running name entity recognition on the data\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Function to extract named entities from a document\n",
    "def extract_entities_from_docs(docs):\n",
    "    entity_lists = []\n",
    "    for doc in docs:\n",
    "        entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"LOC\"] and ent.text.isalpha() and len(ent.text) > 2]\n",
    "        entity_lists.append(entities)\n",
    "    return entity_lists\n",
    "\n",
    "# Loop through all DataFrames\n",
    "for topic, df in cleaned_dataframes.items():\n",
    "    print(f\"Processing topic: {topic}\")\n",
    "    \n",
    "    # Filter out rows with missing data in 'title' and 'content'\n",
    "    df = df.dropna(subset=['title', 'content'])\n",
    "\n",
    "    # nlp.pipe is btch processing\n",
    "    title_docs = nlp.pipe(df['title'], disable=[\"textcat\"])\n",
    "    content_docs = nlp.pipe(df['content'], disable=[\"textcat\"])\n",
    "    \n",
    "    df['Title_Entities'] = extract_entities_from_docs(title_docs)\n",
    "    df['Content_Entities'] = extract_entities_from_docs(content_docs)\n",
    "\n",
    "    # Combine all entity lists into one for counting\n",
    "    all_entities = df['Title_Entities'].sum() + df['Content_Entities'].sum()\n",
    "    \n",
    "    # Calculate the value counts\n",
    "    entity_counts = pd.Series(all_entities).value_counts()\n",
    "    \n",
    "    # Output the top 10 most frequent entities\n",
    "    print(f\"Top entities for {topic}:\\n\", entity_counts.head(10))\n",
    "\n",
    "    # Store the counts for further analysis\n",
    "    cleaned_dataframes[topic]['Entity_Counts'] = entity_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031dbda8",
   "metadata": {},
   "source": [
    "Based on the data, we determined that these were the relevant actors for each topic:\n",
    "\n",
    "* **Election:** Trump, Harris, Biden\n",
    "* **Gaza:** Israel, Hamas, Palestinians\n",
    "* **FEMA:** Trump, Harris\n",
    "* **Abortion**: Trump, Harris, Women\n",
    "* **Unemployment**: Fed, Trump, Harris \n",
    "* **Dockworkers**: Dockworkers\n",
    "* **Immigration**: Trump, Harris, Biden, Haitian\n",
    "\n",
    "In order to process the articles more efficiently for subsequent steps, we decided to remove any sentences that do not contain the above words. Additionally, we will do the following for specific topics:\n",
    "\n",
    "* **Gaza:** Find and Replace Civilian\n",
    "* **Abortion**: Check for instances of \"Woman\" as well\n",
    "* **Dockworkers**: Find and replace Union, International Longshoremen's Association; Find and replace United States Maritime Alliance, USMX\n",
    "* **Immigration**: Find and replace Springfield\n",
    "\n",
    "Our reasoning is that now, the articles will be smaller in size while still retaining all of the articles, and that passive/active voice is not getting affected by non-actor sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c861661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and replace for each of the sentences\n",
    "# For article in a given topic, remove any sentences that do not contain these words. \n",
    "# Idea is that articles are smaller and easier to process while still retaining the articles \n",
    "# Passive/Active voice is not getting affected by non-actor sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d223621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the keywords and find-and-replace mappings for each topic\n",
    "topic_keywords = {\n",
    "    \"Election\": {\n",
    "        \"keywords\": [\"Trump\", \"Harris\", \"Biden\"],\n",
    "    },\n",
    "    \"Gaza\": {\n",
    "        \"keywords\": [\"Israel\", \"Hamas\", \"Palestinians\"],\n",
    "        \"find_replace\": {\"Palestinians\": \"civilian\"}\n",
    "    },\n",
    "    \"FEMA\": {\n",
    "        \"keywords\": [\"Trump\", \"Harris\"],\n",
    "    },\n",
    "    \"Abortion\": {\n",
    "        \"keywords\": [\"Trump\", \"Harris\", \"Women\", \"Woman\"],\n",
    "    },\n",
    "    \"Unemployment\": {\n",
    "        \"keywords\": [\"Fed\", \"Trump\", \"Harris\"],\n",
    "    },\n",
    "    \"Dockworkers\": {\n",
    "        \"keywords\": [\"Dockworkers\", \"Employer\"],\n",
    "        \"find_replace\": {\n",
    "            \"union\": \"Dockworkers\",\n",
    "            \"international longshoremen's association\": \"Dockworkers\",\n",
    "            \"United States Maritime Alliance\": \"Employer\",\n",
    "            \"USMX\": \"Employer\"\n",
    "        }\n",
    "    },\n",
    "    \"Immigration\": {\n",
    "        \"keywords\": [\"Trump\", \"Harris\", \"Biden\", \"Haitian\"],\n",
    "        \"find_replace\": {\"Springfield\": \"Haitian\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to perform find-and-replace operations\n",
    "def apply_find_replace(text, find_replace_dict):\n",
    "    # Build a mapping from lowercased keys to their replacements\n",
    "    lower_find_replace = {k.lower(): v for k, v in find_replace_dict.items()}\n",
    "    # Escape special characters in keys for regex\n",
    "    escaped_keys = [re.escape(k) for k in find_replace_dict.keys()]\n",
    "    pattern = re.compile(\"|\".join(escaped_keys), re.IGNORECASE)\n",
    "    \n",
    "    def replace_match(m):\n",
    "        matched_text = m.group(0)\n",
    "        # Lookup the replacement using the lowercase matched text\n",
    "        replacement = lower_find_replace.get(matched_text.lower(), matched_text)\n",
    "        return replacement\n",
    "    \n",
    "    return pattern.sub(replace_match, text)\n",
    "\n",
    "# Function to filter sentences based on keywords and ensure a keyword threshold is met\n",
    "def filter_sentences(text, keywords, threshold=1):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)  # Split text into sentences\n",
    "    keyword_pattern = re.compile(r'\\b(' + '|'.join(map(re.escape, keywords)) + r')\\b', re.IGNORECASE)\n",
    "    \n",
    "    filtered_sentences = []\n",
    "    keyword_count = 0\n",
    "    \n",
    "    for sent in sentences:\n",
    "        if keyword_pattern.search(sent):\n",
    "            filtered_sentences.append(sent)\n",
    "            keyword_count += len(keyword_pattern.findall(sent))  # Count occurrences of keywords\n",
    "    \n",
    "    # Only return the filtered sentences if the keyword count meets or exceeds the threshold\n",
    "    if keyword_count >= threshold:\n",
    "        return ' '.join(filtered_sentences)\n",
    "    else:\n",
    "        return \"\"  # Return empty if the threshold isn't met\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "08e10685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic: Election\n",
      "Processing topic: Gaza\n",
      "Processing topic: FEMA\n",
      "Processing topic: Abortion\n",
      "Processing topic: Inflation\n",
      "Processing topic: Unemployment\n",
      "Processing topic: Dockworkers\n",
      "Processing topic: Immigration\n"
     ]
    }
   ],
   "source": [
    "# Apply the filtering to each DataFrame\n",
    "threshold = 2  # Set the threshold for how many keywords need to be found to retain the content\n",
    "\n",
    "for topic, df in cleaned_dataframes.items():\n",
    "    print(f\"Processing topic: {topic}\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Get keywords and find-and-replace mappings for the topic\n",
    "    keywords = topic_keywords.get(topic, {}).get('keywords', [])\n",
    "    find_replace = topic_keywords.get(topic, {}).get('find_replace', {})\n",
    "    \n",
    "    # Apply find-and-replace and sentence filtering to 'content' column\n",
    "    filtered_contents = []\n",
    "    for content in df['content']:\n",
    "        # Skip if content is NaN\n",
    "        if pd.isnull(content):\n",
    "            filtered_contents.append(content)\n",
    "            continue\n",
    "        \n",
    "        # Apply find-and-replace operations\n",
    "        if find_replace:\n",
    "            content = apply_find_replace(content, find_replace)\n",
    "        \n",
    "        # Filter sentences based on keywords and threshold\n",
    "        filtered_content = filter_sentences(content, keywords, threshold)\n",
    "        filtered_contents.append(filtered_content)\n",
    "    \n",
    "    # Update the DataFrame with the filtered content in the \"content\" column\n",
    "    df['content'] = filtered_contents\n",
    "    cleaned_dataframes[topic] = df\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file (optional)\n",
    "    # df.to_csv(f\"{topic.replace(' ', '_')}_filtered_articles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2df41f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Election, Original Articles: 1967, After Filtering: 1074\n",
      "Topic: Gaza, Original Articles: 481, After Filtering: 345\n",
      "Topic: FEMA, Original Articles: 1429, After Filtering: 235\n",
      "Topic: Abortion, Original Articles: 539, After Filtering: 385\n",
      "Topic: Unemployment, Original Articles: 183, After Filtering: 70\n",
      "Topic: Dockworkers, Original Articles: 2500, After Filtering: 10\n",
      "Topic: Immigration, Original Articles: 937, After Filtering: 586\n"
     ]
    }
   ],
   "source": [
    "# Create a second version of cleaned_dataframes where articles with empty 'content' are removed\n",
    "cleaned_dataframes_filtered = {}\n",
    "for topic, df in cleaned_dataframes.items():\n",
    "    # Remove rows where 'content' is empty or contains only whitespace\n",
    "    df_filtered = df[df['content'].str.strip().astype(bool)].copy()\n",
    "    cleaned_dataframes_filtered[topic] = df_filtered\n",
    "\n",
    "    # Save the filtered DataFrame to a new CSV file (second version)\n",
    "    # df_filtered.to_csv(f\"{topic.replace(' ', '_')}_filtered_articles_no_empty.csv\", index=False)\n",
    "\n",
    "# Print the number of articles before and after filtering\n",
    "for topic in topic_keywords.keys():\n",
    "    original_count = len(cleaned_dataframes[topic])\n",
    "    filtered_count = len(cleaned_dataframes_filtered[topic])\n",
    "    print(f\"Topic: {topic}, Original Articles: {original_count}, After Filtering: {filtered_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f5d7e6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filtered_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Wait Wait' for October 12, 2024: With Not My ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What the Harris campaign is doing to try to wi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hurricane Evacuation Saves Lives, Mass Gatheri...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Some Democrats are still hesitant to vote for ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harris releases medical report, drawing anothe...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title content filtered_content\n",
       "0  'Wait Wait' for October 12, 2024: With Not My ...                         \n",
       "1  What the Harris campaign is doing to try to wi...                         \n",
       "2  Hurricane Evacuation Saves Lives, Mass Gatheri...                         \n",
       "3  Some Democrats are still hesitant to vote for ...                         \n",
       "4  Harris releases medical report, drawing anothe...                         "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the filtered DataFrame for a topic\n",
    "topic = \"Dockworkers\"\n",
    "cleaned_dataframes[topic][['title', 'content', 'filtered_content']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e9a9127b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'People cheer before former President Donald Trump speaks at a rally at the Gaylord Rockies Resort and Convention Center on Friday in Aurora, Colorado. Michael Ciaglo/Getty Images hide caption\\n\\nSupporters of Donald Trump are getting a rare opportunity to see him rally in the blue state of Colorado, where the former president is expected to bring his hardline immigration message on Friday to a city he has demonized as overrun by migrant crime -- despite pushback from local leaders. Trump has repeatedly name-checked the city of Aurora at speeches and on the debate stage in recent weeks -- likening the Denver suburb to a \"war zone.\" He\\'s amplified claims that a Venezuelan gang has taken over apartment buildings in the city, a situation that elected Republican and Democratic leaders on the ground have said has been overblown and is being dealt with by local and federal law enforcement. Aurora Mayor Mike Coffman, a Republican and long-time Trump critic, said he hoped Trump would take the time to tour the city while he is there on Friday. Coffman\\'s message to Trump? \"I\\'m excited for you to come here so I could show you that the narrative that is being presented nationally about this city isn\\'t true, that there are no apartment complexes under gang control, that the city\\'s not under gang control, Venezuelan gang control.\"\\n\\nBut for Trump backers, his arrival in Colorado is a welcome event, as an estimated 10,000 people filled a hall in Aurora near the airport at Gaylord Rockies, a resort and convention center on the outskirts of a city. The pair were the first in line to see Trump and stayed awake all night outside waiting to get in. It\\'s also their first Trump rally. \"I don\\'t think we should send billions of dollars to Ukraine when there\\'s hurricane victims struggling that pay taxes their whole life.\"\\n\\nTrump supporters said they were excited to hear him talk about his plans for the U.S. She arrived Thursday afternoon and said this will be the 25th Trump rally she\\'s attended since 2016. I say the greatest people you\\'ll ever meet in your life, is at a Trump rally. They\\'ll take the shirt off their back for you.\"\\n\\nShe was standing near 19-year-old Ben Feeney, who lives about an hour away from Aurora and said he loves that Trump is in Colorado to support people in the city, and is proud to vote for Trump in his first presidential election. Meanwhile, ahead of Trump\\'s remarks Democratic state leaders, including Gov. Jared Polis held their own press conference where they promised to \"hold Trump accountable for spreading misinformation about the Aurora community.\"\\n\\nThey also blasted Trump for squelching a bipartisan border deal earlier this year that they said was the most comprehensive immigration reform proposed in the last decade.'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataframes_filtered['Election']['content'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d31a3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleaned_dataframes_filtered['Gaza']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f2ea0bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/TimmyRen/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: NPR\n",
      "  Average bias score for Israel (title): -0.236875\n",
      "  Average bias score for Israel (content): -0.23678096118299446\n",
      "  Average bias score for Hamas (title): -0.2756\n",
      "  Average bias score for Hamas (content): -0.35228115942028987\n",
      "  Average bias score for Gazan (title): 0\n",
      "  Average bias score for Gazan (content): 0\n",
      "Source: MSNBC.com\n",
      "  Average bias score for Israel (title): -0.4992\n",
      "  Average bias score for Israel (content): -0.17121126760563382\n",
      "  Average bias score for Hamas (title): 0\n",
      "  Average bias score for Hamas (content): -0.35925454545454544\n",
      "  Average bias score for Gazan (title): 0\n",
      "  Average bias score for Gazan (content): 0.6771\n",
      "Source: AP NEWS\n",
      "  Average bias score for Israel (title): -0.3912111111111111\n",
      "  Average bias score for Israel (content): -0.2516616099071207\n",
      "  Average bias score for Hamas (title): -0.5664523809523809\n",
      "  Average bias score for Hamas (content): -0.3333086124401914\n",
      "  Average bias score for Gazan (title): 0\n",
      "  Average bias score for Gazan (content): 0\n",
      "Source: Fox News\n",
      "  Average bias score for Israel (title): -0.3312\n",
      "  Average bias score for Israel (content): -0.17377288306451613\n",
      "  Average bias score for Hamas (title): -0.4233782608695652\n",
      "  Average bias score for Hamas (content): -0.2296883259911894\n",
      "  Average bias score for Gazan (title): 0.5106\n",
      "  Average bias score for Gazan (content): -0.25522\n",
      "Source: Forbes\n",
      "  Average bias score for Israel (title): -0.19626428571428572\n",
      "  Average bias score for Israel (content): -0.20056887755102043\n",
      "  Average bias score for Hamas (title): -0.9313\n",
      "  Average bias score for Hamas (content): -0.32556538461538465\n",
      "  Average bias score for Gazan (title): 0\n",
      "  Average bias score for Gazan (content): 0\n"
     ]
    }
   ],
   "source": [
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Assume 'df' is your DataFrame with columns: title, source, content, num_sentences\n",
    "\n",
    "# Perform find and replace\n",
    "df['content'] = df['content'].str.replace('Netanyahu', 'Israel', regex=False)\n",
    "df['content'] = df['content'].str.replace('Palestinan', 'Gazan', regex=False)\n",
    "df['content'] = df['content'].str.replace('Palestinans', 'Gazan', regex=False)\n",
    "df['content'] = df['content'].str.replace('Gazans', 'Gazan', regex=False)\n",
    "# Define the main actors\n",
    "actors = ['Israel', 'Hamas', 'Gazan']\n",
    "\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define the passive voice pattern\n",
    "passive_rule = [\n",
    "    {'DEP': 'nsubjpass'},    # Passive nominal subject\n",
    "    {'DEP': 'aux', 'OP': '*'},   # Optional auxiliary verbs\n",
    "    {'DEP': 'auxpass'},      # Passive auxiliary\n",
    "    {'TAG': 'VBN'}           # Past participle verb\n",
    "]\n",
    "matcher.add('Passive', [passive_rule])\n",
    "\n",
    "# Function to detect passive voice using Matcher\n",
    "def is_passive(doc):\n",
    "    matches = matcher(doc)\n",
    "    return bool(matches)\n",
    "\n",
    "# Batch processing function to handle multiple articles at once\n",
    "def process_batch(batch_df):\n",
    "    actor_scores_batch = {}\n",
    "\n",
    "    # Filter out rows where 'title' or 'content' is missing or empty\n",
    "    batch_df_filtered = batch_df.dropna(subset=['title', 'content']).copy()\n",
    "    batch_df_filtered = batch_df_filtered[batch_df_filtered['title'].str.strip() != \"\"]\n",
    "    batch_df_filtered = batch_df_filtered[batch_df_filtered['content'].str.strip() != \"\"]\n",
    "    \n",
    "    # Ensure filtered DataFrame is reindexed to avoid index mismatch\n",
    "    batch_df_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Process titles and contents together for each article in the batch\n",
    "    docs_titles = list(nlp.pipe(batch_df_filtered['title'].tolist(), batch_size=batch_size))\n",
    "    docs_contents = list(nlp.pipe(batch_df_filtered['content'].tolist(), batch_size=batch_size))\n",
    "\n",
    "    # Process each article in the filtered batch\n",
    "    for idx, row in batch_df_filtered.iterrows():\n",
    "        title_doc = docs_titles[idx]\n",
    "        content_doc = docs_contents[idx]\n",
    "        source = row['source']\n",
    "        \n",
    "        # Initialize actor score dictionary for the source if not present\n",
    "        if source not in actor_scores_batch:\n",
    "            actor_scores_batch[source] = {actor: {'title_scores': [], 'content_scores': []} for actor in actors}\n",
    "\n",
    "        # Function to process sentences (for both content and title)\n",
    "        def process_sentences(sentences, score_type):\n",
    "            relevant_sentences = []\n",
    "            for sentence in sentences:\n",
    "                if any(actor in sentence.text for actor in actors):\n",
    "                    relevant_sentences.append(sentence)\n",
    "\n",
    "            # Process each relevant sentence\n",
    "            for sentence in relevant_sentences:\n",
    "                for actor in actors:\n",
    "                    if actor in sentence.text:\n",
    "                        # Determine voice score\n",
    "                        voice_score = -1 if is_passive(sentence) else 1\n",
    "\n",
    "                        # Determine sentiment score using VADER\n",
    "                        sentiment_scores = sia.polarity_scores(sentence.text)\n",
    "                        sentiment = sentiment_scores['compound']  # Compound score between -1 and 1\n",
    "\n",
    "                        # Multiply voice and sentiment scores\n",
    "                        score = voice_score * sentiment\n",
    "\n",
    "                        # Append the score to the actor's list for the source\n",
    "                        actor_scores_batch[source][actor][score_type].append(score)\n",
    "        \n",
    "        # Process title and content sentences in batch\n",
    "        process_sentences(title_doc.sents, 'title_scores')\n",
    "        process_sentences(content_doc.sents, 'content_scores')\n",
    "\n",
    "    return actor_scores_batch\n",
    "\n",
    "# Batch-level processing setup\n",
    "batch_size = 100  # Define the batch size\n",
    "actor_scores_per_source = {}\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "for start in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[start:start + batch_size]\n",
    "    \n",
    "    # Process each batch\n",
    "    batch_actor_scores = process_batch(batch_df)\n",
    "    \n",
    "    # Merge the batch scores with the overall actor scores\n",
    "    for source, actor_scores in batch_actor_scores.items():\n",
    "        if source not in actor_scores_per_source:\n",
    "            actor_scores_per_source[source] = actor_scores\n",
    "        else:\n",
    "            for actor in actors:\n",
    "                actor_scores_per_source[source][actor]['title_scores'].extend(actor_scores[actor]['title_scores'])\n",
    "                actor_scores_per_source[source][actor]['content_scores'].extend(actor_scores[actor]['content_scores'])\n",
    "\n",
    "# Calculate average scores for each actor per source\n",
    "average_actor_scores_per_source = {}\n",
    "for source, actor_scores in actor_scores_per_source.items():\n",
    "    average_actor_scores_per_source[source] = {}\n",
    "    for actor, scores in actor_scores.items():\n",
    "        avg_title_score = sum(scores['title_scores']) / len(scores['title_scores']) if scores['title_scores'] else 0\n",
    "        avg_content_score = sum(scores['content_scores']) / len(scores['content_scores']) if scores['content_scores'] else 0\n",
    "        average_actor_scores_per_source[source][actor] = {\n",
    "            'average_title_score': avg_title_score,\n",
    "            'average_content_score': avg_content_score\n",
    "        }\n",
    "\n",
    "# Display the average scores per source for both title and content\n",
    "for source, actor_scores in average_actor_scores_per_source.items():\n",
    "    print(f\"Source: {source}\")\n",
    "    for actor, scores in actor_scores.items():\n",
    "        print(f\"  Average bias score for {actor} (title): {scores['average_title_score']}\")\n",
    "        print(f\"  Average bias score for {actor} (content): {scores['average_content_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2103de8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "AP NEWS      145\n",
       "Fox News     127\n",
       "NPR           46\n",
       "Forbes        17\n",
       "MSNBC.com     10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8e8770f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleaned_dataframes_filtered['Election']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "21132eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "Fox News     376\n",
       "Forbes       218\n",
       "MSNBC.com    200\n",
       "AP NEWS      171\n",
       "NPR          109\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "96075b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: NPR\n",
      "  Average bias score for Trump (title): -0.08608571428571428\n",
      "  Average bias score for Trump (content): 0.03656699453551912\n",
      "  Average bias score for Harris (title): 0.01894814814814815\n",
      "  Average bias score for Harris (content): 0.08419402697495183\n",
      "  Average bias score for Biden (title): -0.22666666666666668\n",
      "  Average bias score for Biden (content): -0.00867781954887218\n",
      "Source: MSNBC.com\n",
      "  Average bias score for Trump (title): -0.16685126050420168\n",
      "  Average bias score for Trump (content): 0.0008627684964200481\n",
      "  Average bias score for Harris (title): 0.048414893617021275\n",
      "  Average bias score for Harris (content): 0.10686429872495447\n",
      "  Average bias score for Biden (title): 0.19733333333333333\n",
      "  Average bias score for Biden (content): 0.04760051282051282\n",
      "Source: AP NEWS\n",
      "  Average bias score for Trump (title): -0.1504646153846154\n",
      "  Average bias score for Trump (content): 0.022910641399416908\n",
      "  Average bias score for Harris (title): -0.0528575\n",
      "  Average bias score for Harris (content): 0.06289353383458646\n",
      "  Average bias score for Biden (title): -0.1046875\n",
      "  Average bias score for Biden (content): 0.02667914691943128\n",
      "Source: Fox News\n",
      "  Average bias score for Trump (title): 0.02182876712328767\n",
      "  Average bias score for Trump (content): 0.02703921143847487\n",
      "  Average bias score for Harris (title): -0.030624637681159424\n",
      "  Average bias score for Harris (content): 0.019843848101265823\n",
      "  Average bias score for Biden (title): -0.13252173913043477\n",
      "  Average bias score for Biden (content): -0.012693174061433448\n",
      "Source: Forbes\n",
      "  Average bias score for Trump (title): -0.03091512605042017\n",
      "  Average bias score for Trump (content): 0.06995124223602485\n",
      "  Average bias score for Harris (title): 0.050091489361702136\n",
      "  Average bias score for Harris (content): 0.16727174468085107\n",
      "  Average bias score for Biden (title): 0.3062\n",
      "  Average bias score for Biden (content): 0.08983848039215686\n"
     ]
    }
   ],
   "source": [
    "# Initialize the VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Assume 'df' is your DataFrame with columns: title, source, content, num_sentences\n",
    "\n",
    "# Define the main actors\n",
    "actors = ['Trump', 'Harris', 'Biden']\n",
    "\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define the passive voice pattern\n",
    "passive_rule = [\n",
    "    {'DEP': 'nsubjpass'},    # Passive nominal subject\n",
    "    {'DEP': 'aux', 'OP': '*'},   # Optional auxiliary verbs\n",
    "    {'DEP': 'auxpass'},      # Passive auxiliary\n",
    "    {'TAG': 'VBN'}           # Past participle verb\n",
    "]\n",
    "matcher.add('Passive', [passive_rule])\n",
    "\n",
    "# Function to detect passive voice using Matcher\n",
    "def is_passive(doc):\n",
    "    matches = matcher(doc)\n",
    "    return bool(matches)\n",
    "\n",
    "# Batch processing function to handle multiple articles at once\n",
    "def process_batch(batch_df):\n",
    "    actor_scores_batch = {}\n",
    "\n",
    "    # Filter out rows where 'title' or 'content' is missing or empty\n",
    "    batch_df_filtered = batch_df.dropna(subset=['title', 'content']).copy()\n",
    "    batch_df_filtered = batch_df_filtered[batch_df_filtered['title'].str.strip() != \"\"]\n",
    "    batch_df_filtered = batch_df_filtered[batch_df_filtered['content'].str.strip() != \"\"]\n",
    "    \n",
    "    # Ensure filtered DataFrame is reindexed to avoid index mismatch\n",
    "    batch_df_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Process titles and contents together for each article in the batch\n",
    "    docs_titles = list(nlp.pipe(batch_df_filtered['title'].tolist(), batch_size=batch_size))\n",
    "    docs_contents = list(nlp.pipe(batch_df_filtered['content'].tolist(), batch_size=batch_size))\n",
    "\n",
    "    # Process each article in the filtered batch\n",
    "    for idx, row in batch_df_filtered.iterrows():\n",
    "        title_doc = docs_titles[idx]\n",
    "        content_doc = docs_contents[idx]\n",
    "        source = row['source']\n",
    "        \n",
    "        # Initialize actor score dictionary for the source if not present\n",
    "        if source not in actor_scores_batch:\n",
    "            actor_scores_batch[source] = {actor: {'title_scores': [], 'content_scores': []} for actor in actors}\n",
    "\n",
    "        # Function to process sentences (for both content and title)\n",
    "        def process_sentences(sentences, score_type):\n",
    "            relevant_sentences = []\n",
    "            for sentence in sentences:\n",
    "                if any(actor in sentence.text for actor in actors):\n",
    "                    relevant_sentences.append(sentence)\n",
    "\n",
    "            # Process each relevant sentence\n",
    "            for sentence in relevant_sentences:\n",
    "                for actor in actors:\n",
    "                    if actor in sentence.text:\n",
    "                        # Determine voice score\n",
    "                        voice_score = -1 if is_passive(sentence) else 1\n",
    "\n",
    "                        # Determine sentiment score using VADER\n",
    "                        sentiment_scores = sia.polarity_scores(sentence.text)\n",
    "                        sentiment = sentiment_scores['compound']  # Compound score between -1 and 1\n",
    "\n",
    "                        # Multiply voice and sentiment scores\n",
    "                        score = voice_score * sentiment\n",
    "\n",
    "                        # Append the score to the actor's list for the source\n",
    "                        actor_scores_batch[source][actor][score_type].append(score)\n",
    "        \n",
    "        # Process title and content sentences in batch\n",
    "        process_sentences(title_doc.sents, 'title_scores')\n",
    "        process_sentences(content_doc.sents, 'content_scores')\n",
    "\n",
    "    return actor_scores_batch\n",
    "\n",
    "# Batch-level processing setup\n",
    "batch_size = 100  # Define the batch size\n",
    "actor_scores_per_source = {}\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "for start in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[start:start + batch_size]\n",
    "    \n",
    "    # Process each batch\n",
    "    batch_actor_scores = process_batch(batch_df)\n",
    "    \n",
    "    # Merge the batch scores with the overall actor scores\n",
    "    for source, actor_scores in batch_actor_scores.items():\n",
    "        if source not in actor_scores_per_source:\n",
    "            actor_scores_per_source[source] = actor_scores\n",
    "        else:\n",
    "            for actor in actors:\n",
    "                actor_scores_per_source[source][actor]['title_scores'].extend(actor_scores[actor]['title_scores'])\n",
    "                actor_scores_per_source[source][actor]['content_scores'].extend(actor_scores[actor]['content_scores'])\n",
    "\n",
    "# Calculate average scores for each actor per source\n",
    "average_actor_scores_per_source = {}\n",
    "for source, actor_scores in actor_scores_per_source.items():\n",
    "    average_actor_scores_per_source[source] = {}\n",
    "    for actor, scores in actor_scores.items():\n",
    "        avg_title_score = sum(scores['title_scores']) / len(scores['title_scores']) if scores['title_scores'] else 0\n",
    "        avg_content_score = sum(scores['content_scores']) / len(scores['content_scores']) if scores['content_scores'] else 0\n",
    "        average_actor_scores_per_source[source][actor] = {\n",
    "            'average_title_score': avg_title_score,\n",
    "            'average_content_score': avg_content_score\n",
    "        }\n",
    "\n",
    "# Display the average scores per source for both title and content\n",
    "for source, actor_scores in average_actor_scores_per_source.items():\n",
    "    print(f\"Source: {source}\")\n",
    "    for actor, scores in actor_scores.items():\n",
    "        print(f\"  Average bias score for {actor} (title): {scores['average_title_score']}\")\n",
    "        print(f\"  Average bias score for {actor} (content): {scores['average_content_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf90c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New Env Kernel",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
