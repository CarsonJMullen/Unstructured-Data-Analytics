{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b1dc68",
   "metadata": {},
   "source": [
    "**Members:** Ethan Wong, Timmy Ren, Mason Shu, Medha Nalamada, Carson Mullen, Bethel Kim\n",
    "\n",
    "**Morning Cohort**: 11 AM - 1 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb917e6",
   "metadata": {},
   "source": [
    "# Install and Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4f7e67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "     ---------------------------------------- 0.0/400.7 MB ? eta -:--:--\n",
      "     - ------------------------------------ 14.7/400.7 MB 83.8 MB/s eta 0:00:05\n",
      "     --- ---------------------------------- 32.5/400.7 MB 82.5 MB/s eta 0:00:05\n",
      "     ---- --------------------------------- 48.8/400.7 MB 81.6 MB/s eta 0:00:05\n",
      "     ----- -------------------------------- 57.4/400.7 MB 70.3 MB/s eta 0:00:05\n",
      "     ------ ------------------------------- 70.3/400.7 MB 68.9 MB/s eta 0:00:05\n",
      "     ------- ------------------------------ 83.1/400.7 MB 68.0 MB/s eta 0:00:05\n",
      "     -------- ----------------------------- 89.1/400.7 MB 62.5 MB/s eta 0:00:05\n",
      "     --------- ---------------------------- 96.5/400.7 MB 58.6 MB/s eta 0:00:06\n",
      "     --------- --------------------------- 107.0/400.7 MB 57.9 MB/s eta 0:00:06\n",
      "     ---------- -------------------------- 116.4/400.7 MB 56.7 MB/s eta 0:00:06\n",
      "     ----------- ------------------------- 126.1/400.7 MB 55.5 MB/s eta 0:00:05\n",
      "     ------------ ------------------------ 132.6/400.7 MB 53.3 MB/s eta 0:00:06\n",
      "     ------------ ------------------------ 140.8/400.7 MB 52.0 MB/s eta 0:00:06\n",
      "     ------------- ----------------------- 148.9/400.7 MB 50.9 MB/s eta 0:00:05\n",
      "     -------------- ---------------------- 157.8/400.7 MB 50.2 MB/s eta 0:00:05\n",
      "     --------------- --------------------- 164.4/400.7 MB 49.1 MB/s eta 0:00:05\n",
      "     --------------- --------------------- 170.7/400.7 MB 47.8 MB/s eta 0:00:05\n",
      "     ---------------- -------------------- 174.6/400.7 MB 47.3 MB/s eta 0:00:05\n",
      "     ---------------- -------------------- 179.0/400.7 MB 44.9 MB/s eta 0:00:05\n",
      "     ----------------- ------------------- 185.3/400.7 MB 44.2 MB/s eta 0:00:05\n",
      "     ----------------- ------------------- 191.9/400.7 MB 43.5 MB/s eta 0:00:05\n",
      "     ------------------ ------------------ 199.0/400.7 MB 43.0 MB/s eta 0:00:05\n",
      "     ------------------- ----------------- 206.3/400.7 MB 42.7 MB/s eta 0:00:05\n",
      "     ------------------- ----------------- 213.6/400.7 MB 42.3 MB/s eta 0:00:05\n",
      "     -------------------- ---------------- 222.0/400.7 MB 42.1 MB/s eta 0:00:05\n",
      "     --------------------- --------------- 230.7/400.7 MB 42.0 MB/s eta 0:00:05\n",
      "     ---------------------- -------------- 239.6/400.7 MB 42.1 MB/s eta 0:00:04\n",
      "     ---------------------- -------------- 248.8/400.7 MB 42.1 MB/s eta 0:00:04\n",
      "     ----------------------- ------------- 257.9/400.7 MB 42.1 MB/s eta 0:00:04\n",
      "     ------------------------ ------------ 267.6/400.7 MB 41.9 MB/s eta 0:00:04\n",
      "     ------------------------- ----------- 273.9/400.7 MB 41.0 MB/s eta 0:00:04\n",
      "     ------------------------- ----------- 281.3/400.7 MB 40.1 MB/s eta 0:00:03\n",
      "     -------------------------- ---------- 288.1/400.7 MB 39.3 MB/s eta 0:00:03\n",
      "     --------------------------- --------- 293.6/400.7 MB 38.4 MB/s eta 0:00:03\n",
      "     --------------------------- --------- 300.9/400.7 MB 37.8 MB/s eta 0:00:03\n",
      "     ---------------------------- -------- 309.3/400.7 MB 37.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ------- 318.0/400.7 MB 37.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ------- 323.0/400.7 MB 36.5 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 327.2/400.7 MB 35.8 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 334.8/400.7 MB 35.4 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 340.0/400.7 MB 34.8 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 344.5/400.7 MB 34.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 353.6/400.7 MB 34.3 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 362.5/400.7 MB 34.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 367.5/400.7 MB 34.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 374.9/400.7 MB 33.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 384.3/400.7 MB 33.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  394.3/400.7 MB 34.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  397.9/400.7 MB 33.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 33.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 33.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 33.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 33.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 33.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- 400.7/400.7 MB 29.8 MB/s eta 0:00:00\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "#!pip install eventregistry\n",
    "!python -m spacy download en_core_web_lg\n",
    "#!python -m spacy download en_core_web_sm\n",
    "from eventregistry import *\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import spacy # type: ignore\n",
    "from spacy.matcher import Matcher\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1928fbe1",
   "metadata": {},
   "source": [
    "# Scraping Articles with Event Registry API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bcaf719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated DataFrames: ['Election_df']\n"
     ]
    }
   ],
   "source": [
    "# Load the API key from the JSON file\n",
    "with open(\"config.json\", \"r\") as file:\n",
    "    config = json.load(file)\n",
    "api_key = config[\"api_key\"]\n",
    "\n",
    "# Initialize EventRegistry with the API key\n",
    "er = EventRegistry(apiKey=api_key, allowUseOfArchive=False)\n",
    "\n",
    "# Define topics to search for\n",
    "topics = [\"Election\"]\n",
    "\n",
    "# Define sources to search for and get their URIs\n",
    "source_names = source_names = [\"NPR\", \"MSNBC\", \"AP News\", \"FOX\", \"Forbes\", \"New York Times\", \"Bloomberg\", \"USA Today\", \"Washington Post\", \"Politico\", \"Vox\", \"Oan\", \"Breitbart\", \"Wall Street Journal\"]\n",
    "source_uris = {source: er.getNewsSourceUri(source) for source in source_names}\n",
    "\n",
    "# List to store the names of all generated DataFrames\n",
    "dataframe_names = []\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in topics:\n",
    "    # Get the URI for the concept\n",
    "    concept_uri = er.getConceptUri(topic)\n",
    "    \n",
    "    # List to hold all articles' data for the current topic (across all sources)\n",
    "    articles_data = []\n",
    "    \n",
    "    # Loop through each source individually\n",
    "    for source_name, source_uri in source_uris.items():\n",
    "        # Define the query for each topic and source\n",
    "        q = QueryArticlesIter(\n",
    "            conceptUri=concept_uri,\n",
    "            sourceUri=source_uri,\n",
    "            sourceLocationUri=er.getLocationUri(\"United States\"),  # Only US sources\n",
    "        )\n",
    "\n",
    "        # Fetch and accumulate up to 1000 articles for the current topic from this source\n",
    "        for art in q.execQuery(er, sortBy=\"date\", maxItems=1000):\n",
    "            articles_data.append({\n",
    "                \"title\": art.get(\"title\"),\n",
    "                \"source\": art.get(\"source\", {}).get(\"title\"),\n",
    "                \"author\": art.get(\"author\"),\n",
    "                \"url\": art.get(\"url\"),\n",
    "                \"publishedAt\": art.get(\"dateTime\"),\n",
    "                \"content\": art.get(\"body\")\n",
    "            })\n",
    "\n",
    "    # Create a single DataFrame for the current topic with articles from all sources\n",
    "    articles_df = pd.DataFrame(articles_data)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_name = f\"{topic.replace(' ', '_')}_articles.csv\"\n",
    "    articles_df.to_csv(file_name, index=False)\n",
    "\n",
    "    # Dynamically set the DataFrame name based on the topic, replacing spaces with underscores\n",
    "    df_name = f\"{topic.replace(' ', '_')}_df\"\n",
    "    globals()[df_name] = articles_df\n",
    "\n",
    "    # Append the DataFrame name to the list\n",
    "    dataframe_names.append(df_name)\n",
    "\n",
    "# Print the list of all generated DataFrame names\n",
    "print(\"Generated DataFrames:\", dataframe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7e9fb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "Fox News                    905\n",
       "The New York Times          823\n",
       "AP NEWS                     779\n",
       "Washington Post             726\n",
       "POLITICO                    710\n",
       "USA Today                   507\n",
       "Breitbart                   505\n",
       "Forbes                      442\n",
       "Bloomberg Business          410\n",
       "MSNBC.com                   259\n",
       "NPR                         220\n",
       "One America News Network     88\n",
       "The Wall Street Journal      45\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Election_df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1055b4b",
   "metadata": {},
   "source": [
    "# Cleaning Dataframes and Running Name Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f3f3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in CSVs dynamically\n",
    "\n",
    "topics = [\"Election\"]\n",
    "\n",
    "# Dictionary to hold the DataFrames after reading them from CSV\n",
    "dataframes = {}\n",
    "\n",
    "# Loop to read each CSV and store the DataFrame in the dictionary\n",
    "for topic in topics:\n",
    "    # Replace spaces with underscores to match your file naming convention\n",
    "    file_name = f\"{topic.replace(' ', '_')}_articles.csv\"\n",
    "    try:\n",
    "        dataframes[topic.replace(' ', '_')] = pd.read_csv(file_name)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")  # If a file is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46875a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframes\n",
    "def count_sentences(text):\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    return len([s for s in sentences if s.strip()])\n",
    "\n",
    "def clean_df(df):\n",
    "    df = df.drop_duplicates().copy()\n",
    "    df.loc[:, 'content'] = df['content'].str.replace(\n",
    "        \"By entering your email and pushing continue, you are agreeing to Fox News\\' Terms of Use and Privacy Policy, which includes our Notice of Financial Incentive.\\n\\n\", \n",
    "        \"\", \n",
    "        regex=False\n",
    "    )\n",
    "    df.loc[:, 'num_sentences'] = df['content'].apply(count_sentences)\n",
    "    return df\n",
    "\n",
    "# Apply clean_df to each DataFrame in the dictionary\n",
    "cleaned_dataframes = {key: clean_df(df) for key, df in dataframes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2127e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic: Election\n",
      "Top entities for Election:\n",
      " Trump           25979\n",
      "Harris          14472\n",
      "Biden            7055\n",
      "Vance            3639\n",
      "Senate           2773\n",
      "Israel           2675\n",
      "House            2608\n",
      "Pennsylvania     2595\n",
      "GOP              2472\n",
      "Florida          2348\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Running name entity recognition on the data\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Function to extract named entities from a document\n",
    "def extract_entities_from_docs(docs):\n",
    "    entity_lists = []\n",
    "    for doc in docs:\n",
    "        entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"LOC\"] and ent.text.isalpha() and len(ent.text) > 2]\n",
    "        entity_lists.append(entities)\n",
    "    return entity_lists\n",
    "\n",
    "# Loop through all DataFrames\n",
    "for topic, df in cleaned_dataframes.items():\n",
    "    print(f\"Processing topic: {topic}\")\n",
    "    \n",
    "    # Filter out rows with missing data in 'title' and 'content'\n",
    "    df = df.dropna(subset=['title', 'content'])\n",
    "\n",
    "    # nlp.pipe is btch processing\n",
    "    title_docs = nlp.pipe(df['title'], disable=[\"textcat\"])\n",
    "    content_docs = nlp.pipe(df['content'], disable=[\"textcat\"])\n",
    "    \n",
    "    df['Title_Entities'] = extract_entities_from_docs(title_docs)\n",
    "    df['Content_Entities'] = extract_entities_from_docs(content_docs)\n",
    "\n",
    "    # Combine all entity lists into one for counting\n",
    "    all_entities = df['Title_Entities'].sum() + df['Content_Entities'].sum()\n",
    "    \n",
    "    # Calculate the value counts\n",
    "    entity_counts = pd.Series(all_entities).value_counts()\n",
    "    \n",
    "    # Output the top 10 most frequent entities\n",
    "    print(f\"Top entities for {topic}:\\n\", entity_counts.head(10))\n",
    "\n",
    "    # Store the counts for further analysis\n",
    "    cleaned_dataframes[topic]['Entity_Counts'] = entity_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031dbda8",
   "metadata": {},
   "source": [
    "Based on the data, we determined that these were the relevant actors for each topic:\n",
    "\n",
    "* **Election:** Trump, Harris, Biden\n",
    "\n",
    "In order to process the articles more efficiently for subsequent steps, we decided to remove any sentences that do not contain the above words. Our reasoning is that now, the articles will be smaller in size while still retaining all of the articles, and that passive/active voice is not getting affected by non-actor sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c861661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and replace for each of the sentences\n",
    "# For article in a given topic, remove any sentences that do not contain these words. \n",
    "# Idea is that articles are smaller and easier to process while still retaining the articles \n",
    "# Passive/Active voice is not getting affected by non-actor sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d223621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the keywords and find-and-replace mappings for each topic\n",
    "topic_keywords = {\n",
    "    \"Election\": {\n",
    "        \"keywords\": [\"Trump\", \"Harris\", \"Biden\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Function to perform find-and-replace operations\n",
    "def apply_find_replace(text, find_replace_dict):\n",
    "    # Build a mapping from lowercased keys to their replacements\n",
    "    lower_find_replace = {k.lower(): v for k, v in find_replace_dict.items()}\n",
    "    # Escape special characters in keys for regex\n",
    "    escaped_keys = [re.escape(k) for k in find_replace_dict.keys()]\n",
    "    pattern = re.compile(\"|\".join(escaped_keys), re.IGNORECASE)\n",
    "    \n",
    "    def replace_match(m):\n",
    "        matched_text = m.group(0)\n",
    "        # Lookup the replacement using the lowercase matched text\n",
    "        replacement = lower_find_replace.get(matched_text.lower(), matched_text)\n",
    "        return replacement\n",
    "    \n",
    "    return pattern.sub(replace_match, text)\n",
    "\n",
    "# Function to filter sentences based on keywords and ensure a keyword threshold is met\n",
    "def filter_sentences(text, keywords, threshold=1):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)  # Split text into sentences\n",
    "    keyword_pattern = re.compile(r'\\b(' + '|'.join(map(re.escape, keywords)) + r')\\b', re.IGNORECASE)\n",
    "    \n",
    "    filtered_sentences = []\n",
    "    keyword_count = 0\n",
    "    \n",
    "    for sent in sentences:\n",
    "        if keyword_pattern.search(sent):\n",
    "            filtered_sentences.append(sent)\n",
    "            keyword_count += len(keyword_pattern.findall(sent))  # Count occurrences of keywords\n",
    "    \n",
    "    # Only return the filtered sentences if the keyword count meets or exceeds the threshold\n",
    "    if keyword_count >= threshold:\n",
    "        return ' '.join(filtered_sentences)\n",
    "    else:\n",
    "        return \"\"  # Return empty if the threshold isn't met\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08e10685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic: Election\n"
     ]
    }
   ],
   "source": [
    "# Apply the filtering to each DataFrame\n",
    "threshold = 3  # Set the threshold for how many keywords need to be found to retain the content\n",
    "\n",
    "for topic, df in cleaned_dataframes.items():\n",
    "    print(f\"Processing topic: {topic}\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Get keywords and find-and-replace mappings for the topic\n",
    "    keywords = topic_keywords.get(topic, {}).get('keywords', [])\n",
    "    find_replace = topic_keywords.get(topic, {}).get('find_replace', {})\n",
    "    \n",
    "    # Apply find-and-replace and sentence filtering to 'content' column\n",
    "    filtered_contents = []\n",
    "    for content in df['content']:\n",
    "        # Skip if content is NaN\n",
    "        if pd.isnull(content):\n",
    "            filtered_contents.append(content)\n",
    "            continue\n",
    "        \n",
    "        # Apply find-and-replace operations\n",
    "        if find_replace:\n",
    "            content = apply_find_replace(content, find_replace)\n",
    "        \n",
    "        # Filter sentences based on keywords and threshold\n",
    "        filtered_content = filter_sentences(content, keywords, threshold)\n",
    "        filtered_contents.append(filtered_content)\n",
    "    \n",
    "    # Update the DataFrame with the filtered content in the \"content\" column\n",
    "    df['content'] = filtered_contents\n",
    "    cleaned_dataframes[topic] = df\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file (optional)\n",
    "    # df.to_csv(f\"{topic.replace(' ', '_')}_filtered_articles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2df41f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Election, Original Articles: 6419, After Filtering: 4212\n"
     ]
    }
   ],
   "source": [
    "# Create a second version of cleaned_dataframes where articles with empty 'content' are removed\n",
    "cleaned_dataframes_filtered = {}\n",
    "for topic, df in cleaned_dataframes.items():\n",
    "    # Remove rows where 'content' is empty or contains only whitespace\n",
    "    df_filtered = df[df['content'].str.strip().astype(bool)].copy()\n",
    "    cleaned_dataframes_filtered[topic] = df_filtered\n",
    "\n",
    "    # Save the filtered DataFrame to a new CSV file (second version)\n",
    "    # df_filtered.to_csv(f\"{topic.replace(' ', '_')}_filtered_articles_no_empty.csv\", index=False)\n",
    "\n",
    "# Print the number of articles before and after filtering\n",
    "for topic in topic_keywords.keys():\n",
    "    original_count = len(cleaned_dataframes[topic])\n",
    "    filtered_count = len(cleaned_dataframes_filtered[topic])\n",
    "    print(f\"Topic: {topic}, Original Articles: {original_count}, After Filtering: {filtered_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9a9127b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This presidential campaign, former President Donald Trump and other Republicans have been repeating the false narrative that Democrats are purposefully letting migrants into the country so they will vote. Nevertheless, Trump seized on and distorted Richman\\'s estimates to fuel false claims in 2016 that millions of noncitizens had illegally voted. One false narrative this campaign season suggests that the people who arrived at the U.S.-Mexico border during the Biden administration can quickly become citizens and vote legally. Furthermore, changes to asylum protocols during the Biden administration have made it harder to pursue asylum in this country and eventually become a citizen. By focusing on baseless allegations about noncitizens voting in the upcoming election, Trump and his allies appear to be laying the groundwork for potentially contesting the election. \"You can absolutely bet if Trump loses, he will claim there was widespread noncitizen voting without any evidence whatsoever,\" David Becker, the executive director of the Center for Election Innovation and Research told NPR last month.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataframes_filtered['Election']['content'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284faed",
   "metadata": {},
   "source": [
    "# Performing Bias Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e8770f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleaned_dataframes_filtered['Election']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21132eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "Fox News                    754\n",
       "Washington Post             564\n",
       "POLITICO                    554\n",
       "The New York Times          529\n",
       "USA Today                   391\n",
       "Breitbart                   374\n",
       "AP NEWS                     343\n",
       "Forbes                      232\n",
       "MSNBC.com                   222\n",
       "NPR                         124\n",
       "One America News Network     61\n",
       "Bloomberg Business           54\n",
       "The Wall Street Journal      10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96075b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: NPR\n",
      "  Average bias score for Trump (title): -0.09212619047619047\n",
      "  Average bias score for Trump (content): 0.036158053691275165\n",
      "  Average bias score for Harris (title): 0.0028480000000000007\n",
      "  Average bias score for Harris (content): 0.09278663967611335\n",
      "  Average bias score for Biden (title): -0.22666666666666668\n",
      "  Average bias score for Biden (content): 0.008695256916996047\n",
      "Source: MSNBC.com\n",
      "  Average bias score for Trump (title): -0.180035593220339\n",
      "  Average bias score for Trump (content): 0.00023195816385822223\n",
      "  Average bias score for Harris (title): 0.029656818181818187\n",
      "  Average bias score for Harris (content): 0.10562875\n",
      "  Average bias score for Biden (title): 0.19733333333333333\n",
      "  Average bias score for Biden (content): 0.024384433962264147\n",
      "Source: AP NEWS\n",
      "  Average bias score for Trump (title): -0.1215045045045045\n",
      "  Average bias score for Trump (content): 0.02871786501985002\n",
      "  Average bias score for Harris (title): -0.04120897435897436\n",
      "  Average bias score for Harris (content): 0.09194948096885813\n",
      "  Average bias score for Biden (title): -0.10922499999999999\n",
      "  Average bias score for Biden (content): 0.0307892749244713\n",
      "Source: Fox News\n",
      "  Average bias score for Trump (title): -0.01902467105263158\n",
      "  Average bias score for Trump (content): 0.01704540747411076\n",
      "  Average bias score for Harris (title): -0.021560714285714287\n",
      "  Average bias score for Harris (content): 0.034440089285714286\n",
      "  Average bias score for Biden (title): -0.1260975\n",
      "  Average bias score for Biden (content): -0.01399496402877698\n",
      "Source: Forbes\n",
      "  Average bias score for Trump (title): -0.044556637168141594\n",
      "  Average bias score for Trump (content): 0.07092075342465753\n",
      "  Average bias score for Harris (title): 0.016858536585365853\n",
      "  Average bias score for Harris (content): 0.17309098837209302\n",
      "  Average bias score for Biden (title): 0.25142857142857145\n",
      "  Average bias score for Biden (content): 0.11686779220779221\n",
      "Source: The New York Times\n",
      "  Average bias score for Trump (title): -0.058143540669856456\n",
      "  Average bias score for Trump (content): 0.024723702923360548\n",
      "  Average bias score for Harris (title): 0.03200701754385965\n",
      "  Average bias score for Harris (content): 0.06172783278327833\n",
      "  Average bias score for Biden (title): -0.03470769230769231\n",
      "  Average bias score for Biden (content): 0.021868181818181818\n",
      "Source: Bloomberg Business\n",
      "  Average bias score for Trump (title): 0.09368947368421053\n",
      "  Average bias score for Trump (content): 0.09976132075471698\n",
      "  Average bias score for Harris (title): 0.11685666666666666\n",
      "  Average bias score for Harris (content): 0.14304204545454546\n",
      "  Average bias score for Biden (title): -0.123475\n",
      "  Average bias score for Biden (content): 0.06299210526315789\n",
      "Source: USA Today\n",
      "  Average bias score for Trump (title): -0.1377780487804878\n",
      "  Average bias score for Trump (content): 0.00857206015037594\n",
      "  Average bias score for Harris (title): -0.11210325203252033\n",
      "  Average bias score for Harris (content): 0.07441787139689579\n",
      "  Average bias score for Biden (title): -0.13104\n",
      "  Average bias score for Biden (content): 0.018999138991389913\n",
      "Source: Washington Post\n",
      "  Average bias score for Trump (title): -0.1449391089108911\n",
      "  Average bias score for Trump (content): 0.0010276801838778526\n",
      "  Average bias score for Harris (title): 0.024289189189189184\n",
      "  Average bias score for Harris (content): 0.08906353555120679\n",
      "  Average bias score for Biden (title): -0.076671875\n",
      "  Average bias score for Biden (content): 0.0047234240212342396\n",
      "Source: POLITICO\n",
      "  Average bias score for Trump (title): -0.06295481481481481\n",
      "  Average bias score for Trump (content): 0.020396298241008137\n",
      "  Average bias score for Harris (title): 0.02350526315789474\n",
      "  Average bias score for Harris (content): 0.0826347775175644\n",
      "  Average bias score for Biden (title): -0.08332962962962963\n",
      "  Average bias score for Biden (content): 0.033609140767824494\n",
      "Source: One America News Network\n",
      "  Average bias score for Trump (title): -0.04249166666666667\n",
      "  Average bias score for Trump (content): 0.014270833333333333\n",
      "  Average bias score for Harris (title): 0.013847058823529414\n",
      "  Average bias score for Harris (content): 0.07391419354838709\n",
      "  Average bias score for Biden (title): -0.0858\n",
      "  Average bias score for Biden (content): 0.0276125\n",
      "Source: Breitbart\n",
      "  Average bias score for Trump (title): -0.01462777777777778\n",
      "  Average bias score for Trump (content): 0.05233496868475991\n",
      "  Average bias score for Harris (title): -0.056962043795620435\n",
      "  Average bias score for Harris (content): 0.06339787234042553\n",
      "  Average bias score for Biden (title): -0.10548\n",
      "  Average bias score for Biden (content): -0.0015760233918128638\n",
      "Source: The Wall Street Journal\n",
      "  Average bias score for Trump (title): -0.02993333333333333\n",
      "  Average bias score for Trump (content): 0.03312129032258065\n",
      "  Average bias score for Harris (title): -0.1909\n",
      "  Average bias score for Harris (content): 0.1282314606741573\n",
      "  Average bias score for Biden (title): 0\n",
      "  Average bias score for Biden (content): 0.03490465116279069\n"
     ]
    }
   ],
   "source": [
    "# Initialize the VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Assume 'df' is your DataFrame with columns: title, source, content, num_sentences\n",
    "\n",
    "# Define the main actors\n",
    "actors = ['Trump', 'Harris', 'Biden']\n",
    "\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define the passive voice pattern\n",
    "passive_rule = [\n",
    "    {'DEP': 'nsubjpass'},    # Passive nominal subject\n",
    "    {'DEP': 'aux', 'OP': '*'},   # Optional auxiliary verbs\n",
    "    {'DEP': 'auxpass'},      # Passive auxiliary\n",
    "    {'TAG': 'VBN'}           # Past participle verb\n",
    "]\n",
    "matcher.add('Passive', [passive_rule])\n",
    "\n",
    "# Function to detect passive voice using Matcher\n",
    "def is_passive(doc):\n",
    "    matches = matcher(doc)\n",
    "    return bool(matches)\n",
    "\n",
    "# Batch processing function to handle multiple articles at once\n",
    "def process_batch(batch_df):\n",
    "    actor_scores_batch = {}\n",
    "\n",
    "    # Filter out rows where 'title' or 'content' is missing or empty\n",
    "    batch_df_filtered = batch_df.dropna(subset=['title', 'content']).copy()\n",
    "    batch_df_filtered = batch_df_filtered[batch_df_filtered['title'].str.strip() != \"\"]\n",
    "    batch_df_filtered = batch_df_filtered[batch_df_filtered['content'].str.strip() != \"\"]\n",
    "    \n",
    "    # Ensure filtered DataFrame is reindexed to avoid index mismatch\n",
    "    batch_df_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Process titles and contents together for each article in the batch\n",
    "    docs_titles = list(nlp.pipe(batch_df_filtered['title'].tolist(), batch_size=batch_size))\n",
    "    docs_contents = list(nlp.pipe(batch_df_filtered['content'].tolist(), batch_size=batch_size))\n",
    "\n",
    "    # Process each article in the filtered batch\n",
    "    for idx, row in batch_df_filtered.iterrows():\n",
    "        title_doc = docs_titles[idx]\n",
    "        content_doc = docs_contents[idx]\n",
    "        source = row['source']\n",
    "        \n",
    "        # Initialize actor score dictionary for the source if not present\n",
    "        if source not in actor_scores_batch:\n",
    "            actor_scores_batch[source] = {actor: {'title_scores': [], 'content_scores': []} for actor in actors}\n",
    "\n",
    "        # Function to process sentences (for both content and title)\n",
    "        def process_sentences(sentences, score_type):\n",
    "            relevant_sentences = []\n",
    "            for sentence in sentences:\n",
    "                if any(actor in sentence.text for actor in actors):\n",
    "                    relevant_sentences.append(sentence)\n",
    "\n",
    "            # Process each relevant sentence\n",
    "            for sentence in relevant_sentences:\n",
    "                for actor in actors:\n",
    "                    if actor in sentence.text:\n",
    "                        # Determine voice score\n",
    "                        voice_score = -1 if is_passive(sentence) else 1\n",
    "\n",
    "                        # Determine sentiment score using VADER\n",
    "                        sentiment_scores = sia.polarity_scores(sentence.text)\n",
    "                        sentiment = sentiment_scores['compound']  # Compound score between -1 and 1\n",
    "\n",
    "                        # Multiply voice and sentiment scores\n",
    "                        score = voice_score * sentiment\n",
    "\n",
    "                        # Append the score to the actor's list for the source\n",
    "                        actor_scores_batch[source][actor][score_type].append(score)\n",
    "        \n",
    "        # Process title and content sentences in batch\n",
    "        process_sentences(title_doc.sents, 'title_scores')\n",
    "        process_sentences(content_doc.sents, 'content_scores')\n",
    "\n",
    "    return actor_scores_batch\n",
    "\n",
    "# Batch-level processing setup\n",
    "batch_size = 100  # Define the batch size\n",
    "actor_scores_per_source = {}\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "for start in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[start:start + batch_size]\n",
    "    \n",
    "    # Process each batch\n",
    "    batch_actor_scores = process_batch(batch_df)\n",
    "    \n",
    "    # Merge the batch scores with the overall actor scores\n",
    "    for source, actor_scores in batch_actor_scores.items():\n",
    "        if source not in actor_scores_per_source:\n",
    "            actor_scores_per_source[source] = actor_scores\n",
    "        else:\n",
    "            for actor in actors:\n",
    "                actor_scores_per_source[source][actor]['title_scores'].extend(actor_scores[actor]['title_scores'])\n",
    "                actor_scores_per_source[source][actor]['content_scores'].extend(actor_scores[actor]['content_scores'])\n",
    "\n",
    "# Calculate average scores for each actor per source\n",
    "average_actor_scores_per_source = {}\n",
    "for source, actor_scores in actor_scores_per_source.items():\n",
    "    average_actor_scores_per_source[source] = {}\n",
    "    for actor, scores in actor_scores.items():\n",
    "        avg_title_score = sum(scores['title_scores']) / len(scores['title_scores']) if scores['title_scores'] else 0\n",
    "        avg_content_score = sum(scores['content_scores']) / len(scores['content_scores']) if scores['content_scores'] else 0\n",
    "        average_actor_scores_per_source[source][actor] = {\n",
    "            'average_title_score': avg_title_score,\n",
    "            'average_content_score': avg_content_score\n",
    "        }\n",
    "\n",
    "# Display the average scores per source for both title and content\n",
    "for source, actor_scores in average_actor_scores_per_source.items():\n",
    "    print(f\"Source: {source}\")\n",
    "    for actor, scores in actor_scores.items():\n",
    "        print(f\"  Average bias score for {actor} (title): {scores['average_title_score']}\")\n",
    "        print(f\"  Average bias score for {actor} (content): {scores['average_content_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf90c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
