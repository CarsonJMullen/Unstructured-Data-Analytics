{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b4cb879-9377-4df4-b1d6-c155f3280a0c",
   "metadata": {},
   "source": [
    "**Team Members: Ethan Wong, Timmy Ren, Mason Shu, Medha Nalamada, Carson Mullen, Bethel Kim**\n",
    "\n",
    "**Morning Cohort (11 AM - 1 PM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b6562-292d-4ffe-a12b-3c2614e483d8",
   "metadata": {},
   "source": [
    "*Note to all: Please pull any changes from the repo before working on this file!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d2be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Libraries\n",
    "# !pip install deep-translator\n",
    "# !pip install langdetect\n",
    "# !pip install vaderSentiment\n",
    "# !pip install openai==0.27.2\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454091d9-68eb-4a66-b740-e0c067393f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException,\n",
    "    NoSuchElementException,\n",
    "    ElementClickInterceptedException,\n",
    "    WebDriverException,\n",
    ")\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "from deep_translator import GoogleTranslator\n",
    "from langdetect import detect\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import openai\n",
    "import spacy # type: ignore\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699e527-081d-4a2c-b17e-5c2d5055f1d4",
   "metadata": {},
   "source": [
    "# Task A: Scrape from ratebeer.com - extract 5-6K reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_cookie_consent():\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.ID, \"onetrust-banner-sdk\"))\n",
    "        )\n",
    "        accept_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[@id='onetrust-accept-btn-handler']\"))\n",
    "        )\n",
    "        accept_button.click()\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.invisibility_of_element_located((By.ID, \"onetrust-banner-sdk\"))\n",
    "        )\n",
    "    except (TimeoutException, NoSuchElementException, WebDriverException):\n",
    "        pass\n",
    "\n",
    "def handle_ratebeer_banner():\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'RateBeerBestBanner___StyledDiv-jAauHc'))\n",
    "        )\n",
    "        close_button = driver.find_element(By.CSS_SELECTOR, '.RateBeerBestBanner___StyledDiv-jAauHc .MuiIconButton-root')\n",
    "        close_button.click()\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.invisibility_of_element_located((By.CLASS_NAME, 'RateBeerBestBanner___StyledDiv-jAauHc'))\n",
    "        )\n",
    "    except (TimeoutException, NoSuchElementException, WebDriverException):\n",
    "        pass\n",
    "\n",
    "json_file_path = 'beer_reviews.json'\n",
    "with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write('[')\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()), options=chrome_options\n",
    ")\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "# Navigate to the RateBeer Top Beers page\n",
    "driver.get(\"https://www.ratebeer.com/top-beers\")\n",
    "\n",
    "handle_cookie_consent()\n",
    "\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located(\n",
    "        (By.XPATH, \"//div[contains(@class,'DataTable__Row')]/div[2]/a\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Get the list of beers and their links\n",
    "beer_elements = driver.find_elements(By.XPATH, \"//div[contains(@class,'DataTable__Row')]/div[2]/a\")\n",
    "beers = []\n",
    "for beer_element in beer_elements:\n",
    "    full_text = beer_element.text\n",
    "    product_name = full_text.split('\\n')[0]  # Take the first line before the newline\n",
    "    product_link = beer_element.get_attribute('href')\n",
    "    beers.append({'name': product_name, 'link': product_link})\n",
    "\n",
    "total_reviews_collected = 0\n",
    "max_reviews = 30000  # Set your desired number of reviews to collect\n",
    "first_review = True  # Flag to handle commas in JSON\n",
    "\n",
    "# Loop through all beers\n",
    "for i in range(len(beers)):\n",
    "    product_name = beers[i]['name']\n",
    "    product_link = beers[i]['link']\n",
    "\n",
    "    # Navigate to the beer page\n",
    "    driver.get(product_link)\n",
    "\n",
    "    handle_cookie_consent()\n",
    "    handle_ratebeer_banner()\n",
    "\n",
    "    # Wait for the dropdown to be present\n",
    "    try:\n",
    "        dropdown = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"MuiSelect-selectMenu\"))\n",
    "        )\n",
    "        dropdown.click()\n",
    "\n",
    "        # Wait for the dropdown options to be visible\n",
    "        option_100 = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//li[contains(text(), '100')]\"))\n",
    "        )\n",
    "        option_100.click()\n",
    "    except (TimeoutException, NoSuchElementException, WebDriverException):\n",
    "        continue\n",
    "\n",
    "    # Get the total number of reviews\n",
    "    try:\n",
    "        num_items_text = driver.find_element(By.CSS_SELECTOR, \".MuiTablePagination-selectRoot + .MuiTypography-colorInherit\").text\n",
    "        total_reviews = int(num_items_text.split(\" \")[-1])\n",
    "        num_pages = int(np.ceil(total_reviews / 100))\n",
    "    except (NoSuchElementException, ValueError, WebDriverException):\n",
    "        continue\n",
    "\n",
    "    for j in range(num_pages):\n",
    "        time.sleep(2)\n",
    "        # Expand all \"Show more\" buttons\n",
    "        while True:\n",
    "            try:\n",
    "                show_more_button = driver.find_element(By.XPATH, \"//span[text()='Show more']\")\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", show_more_button)\n",
    "                show_more_button.click()\n",
    "                time.sleep(1)\n",
    "            except NoSuchElementException:\n",
    "                break\n",
    "            except ElementClickInterceptedException:\n",
    "                handle_ratebeer_banner()\n",
    "                driver.execute_script(\"arguments[0].click();\", show_more_button)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not click 'Show more' button: {e}\")\n",
    "                break\n",
    "\n",
    "        # Get all comments and store as a list\n",
    "        comments_elements = driver.find_elements(By.CSS_SELECTOR, \".pre-wrap.MuiTypography-body1\")\n",
    "        product_reviews = [comment.text for comment in comments_elements]\n",
    "\n",
    "        rating_elements = driver.find_elements(By.CSS_SELECTOR, \".bRPQdN.MuiTypography-subtitle1\")\n",
    "        ratings = [rating.text for rating in rating_elements]\n",
    "\n",
    "        beer_data_list = []\n",
    "\n",
    "        for review, rating in zip(product_reviews, ratings):\n",
    "            beer_data = {\n",
    "                'product_name': product_name,\n",
    "                'product_review': review,\n",
    "                'rating': rating\n",
    "            }\n",
    "            beer_data_list.append(beer_data)\n",
    "            total_reviews_collected += 1\n",
    "\n",
    "            if total_reviews_collected >= max_reviews:\n",
    "                break\n",
    "\n",
    "        # Write data to the JSON file\n",
    "        with open(json_file_path, 'a', encoding='utf-8') as f:\n",
    "            for beer_data in beer_data_list:\n",
    "                if not first_review:\n",
    "                    f.write(',\\n')\n",
    "                json.dump(beer_data, f, ensure_ascii=False)\n",
    "                first_review = False\n",
    "        beer_data_list = []\n",
    "\n",
    "        if total_reviews_collected >= max_reviews:\n",
    "            break\n",
    "\n",
    "        if j + 1 < num_pages:\n",
    "            try:\n",
    "                button_to_click = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \".MuiIconButton-colorInherit + .MuiIconButton-colorInherit\"))\n",
    "                )\n",
    "                handle_ratebeer_banner()\n",
    "                button_to_click.click()\n",
    "                time.sleep(1)\n",
    "            except ElementClickInterceptedException:\n",
    "                handle_ratebeer_banner()\n",
    "                driver.execute_script(\"arguments[0].click();\", button_to_click)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not click 'Next' button: {e}\")\n",
    "                break\n",
    "\n",
    "    if total_reviews_collected >= max_reviews:\n",
    "        break\n",
    "\n",
    "# Close the JSON array properly\n",
    "with open(json_file_path, 'a', encoding='utf-8') as f:\n",
    "    f.write(']')\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2aeb76e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toppling Goliath Kentucky Brunch</td>\n",
       "      <td>You need personal informations from companies,...</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toppling Goliath Kentucky Brunch</td>\n",
       "      <td>Bottle after MBCC 2024. Black colour, malty ar...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toppling Goliath Kentucky Brunch</td>\n",
       "      <td>Thank you for sharing this Chris - Black with ...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toppling Goliath Kentucky Brunch</td>\n",
       "      <td>Boxed beer at home, proper glassware. Pitch bl...</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toppling Goliath Kentucky Brunch</td>\n",
       "      <td>From backlog. (As 2018 Vintage) 0,3 litre Bott...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product_name  \\\n",
       "0  Toppling Goliath Kentucky Brunch   \n",
       "1  Toppling Goliath Kentucky Brunch   \n",
       "2  Toppling Goliath Kentucky Brunch   \n",
       "3  Toppling Goliath Kentucky Brunch   \n",
       "4  Toppling Goliath Kentucky Brunch   \n",
       "\n",
       "                                      product_review rating  \n",
       "0  You need personal informations from companies,...    3.3  \n",
       "1  Bottle after MBCC 2024. Black colour, malty ar...    4.5  \n",
       "2  Thank you for sharing this Chris - Black with ...    4.3  \n",
       "3  Boxed beer at home, proper glassware. Pitch bl...    4.7  \n",
       "4  From backlog. (As 2018 Vintage) 0,3 litre Bott...    4.9  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the JSON data into a DataFrame\n",
    "with open('beer_reviews.json', 'r', encoding='utf-8') as file:\n",
    "    beer_reviews = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(beer_reviews)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "deff8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling Reviews\n",
    "freq = pd.DataFrame(df.value_counts('product_name')).reset_index()\n",
    "freq.columns = ['product_name', 'count']\n",
    "filtered_df = df[df['product_name'].isin(freq[freq['count'] > 200]['product_name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1faace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q4/ychz3xr57qzb0djwrtl6s8_40000gn/T/ipykernel_58086/1693224999.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = filtered_df.groupby('product_name', group_keys=False).apply(lambda x: x.sample(min(len(x), 100)))\n"
     ]
    }
   ],
   "source": [
    "sampled_df = filtered_df.groupby('product_name', group_keys=False).apply(lambda x: x.sample(min(len(x), 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf7ed085",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampled_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sampled_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sampled_df' is not defined"
     ]
    }
   ],
   "source": [
    "sampled_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7536a183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name\n",
       "3 Fonteinen J & J Oude Geuze Blauw                          100\n",
       "3 Fonteinen Oude Geuze 1998 (50th Anniversary)              100\n",
       "Trappistes Rochefort 10                                     100\n",
       "Toppling Goliath Mornin' Delight                            100\n",
       "Three Floyds Dark Lord - Bourbon Vanilla Bean               100\n",
       "Three Floyds Dark Lord - Bourbon Barrel Aged                100\n",
       "Russian River Pliny the Younger                             100\n",
       "Perennial Abraxas - Barrel-Aged                             100\n",
       "Närke Kaggen Stormaktsporter                                100\n",
       "La Face Cachée de la Pomme Neige Récolte d'Hiver            100\n",
       "Goose Island Bourbon County Stout - Rare 2010               100\n",
       "Goose Island Bourbon County Stout - Proprietor's 2013       100\n",
       "Founders KBS (Kentucky Breakfast Stout)                     100\n",
       "Founders CBS (Canadian Breakfast Stout)                     100\n",
       "De Dolle Stille Nacht Reserva 2000                          100\n",
       "Cigar City Hunahpu's Imperial Stout - Double Barrel Aged    100\n",
       "Cigar City Hunahpu's Imperial Stout                         100\n",
       "Bell's Black Note Stout                                     100\n",
       "AleSmith Speedway Stout - Bourbon Barrel Aged               100\n",
       "AleSmith Speedway Stout - Barrel-Aged Vietnamese Coffee     100\n",
       "AleSmith Speedway Stout                                     100\n",
       "Westvleteren 12                                             100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.value_counts('product_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61c1e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled_df.to_csv('sampled_beer_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abcca19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate text to English if it's not already in English\n",
    "def translate_to_english_if_needed(text):\n",
    "    try:\n",
    "        # Detect the language of the text\n",
    "        lang = detect(text)\n",
    "        # Translate only if the language is not English\n",
    "        if lang != 'en':\n",
    "            translated = GoogleTranslator(source='auto', target='en').translate(text)\n",
    "            return translated\n",
    "        else:\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Apply the translation function to the 'product_review' column\n",
    "sampled_df['product_review'] = sampled_df['product_review'].apply(translate_to_english_if_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60899f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV or json file to prevent re-running the code in the future\n",
    "#sampled_df.to_csv('final_beer_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3a479-7c02-489b-bbff-c64dfda73210",
   "metadata": {},
   "source": [
    "# Task B: Perform a word frequency analysis to find the most important beer attributes and ensure that the attributes specified are likely to be mentioned together in a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc587e7-1f87-457c-a0c0-73ecb2b97873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 Attributes:\n",
      " 227         sweet\n",
      "196         light\n",
      "457        smooth\n",
      "212          rich\n",
      "835        bitter\n",
      "220        creamy\n",
      "536      balanced\n",
      "172           dry\n",
      "177          sour\n",
      "770          thin\n",
      "87         fruity\n",
      "282        citrus\n",
      "736       warming\n",
      "191          tart\n",
      "913         malty\n",
      "441         spicy\n",
      "1656        burnt\n",
      "458         woody\n",
      "349        earthy\n",
      "284     lingering\n",
      "637       peppery\n",
      "549          oaky\n",
      "281        floral\n",
      "2426        hoppy\n",
      "994        mellow\n",
      "Name: Word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Load final reviews dataframe \n",
    "df = pd.read_csv('final_beer_reviews.csv')\n",
    "\n",
    "#Word frequency analysis of entire df \n",
    "df['product_review'] = df['product_review'].apply(str)\n",
    "all_text = ' '.join(df['product_review'].dropna())\n",
    "words = re.findall(r'\\w+', all_text.lower())\n",
    "word_counts = Counter(words)\n",
    "word_freq_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "#Define a common list of attributes to search through \n",
    "attributes = [\n",
    "    'aggressive', 'balanced', 'crisp', 'sweet', 'diacetyl', 'estery', 'floral', 'fruity', 'malty', \n",
    "    'robust', 'light', 'hoppy', 'bitter', 'clove', 'dry', 'earthy', 'herbal', 'nutty', 'piney', \n",
    "    'spicy', 'tart', 'woody', 'creamy', 'toast', 'smooth', 'oaky',\n",
    "    'peppery', 'zesty', 'citrus', 'pungent', 'sour', 'smoky', 'fragrant', 'lingering',\n",
    "    'thin', 'yeasty', 'burnt', 'rich', 'mellow', 'clean', 'dank', \n",
    "    'warming',\n",
    "]\n",
    "\n",
    "attribute_freq = word_freq_df[word_freq_df['Word'].isin(attributes)]\n",
    "top_attributes = attribute_freq.sort_values(by='Frequency', ascending=False)\n",
    "top_25_attributes = top_attributes[:25]['Word']\n",
    "top_25_attributes_list = top_25_attributes.str.lower().tolist()\n",
    "print('Top 25 Attributes:\\n', top_25_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d12795",
   "metadata": {},
   "source": [
    "Before we select 3 attributes, doing a lift analysis will help us see strongly co-occuring attributes that can be used as an ideal selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112dace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing a lift analysis to assess their associations within a message\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Top 3 attributes\n",
    "input_attributes = top_25_attributes_list\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\W+', ' ', text.lower())  # Remove punctuation and convert to lowercase\n",
    "    words = text.split()\n",
    "    return words \n",
    "\n",
    "def find_attribute_pairs(message, attributes, window=50):\n",
    "    message = re.sub(r'\\W+', ' ', message.lower())  # Clean the message\n",
    "    words = message.split()\n",
    "    attribute_indices = {attribute: [] for attribute in attributes}\n",
    "\n",
    "    # Track the position of each attribute in the message\n",
    "    for i, word in enumerate(words):\n",
    "        if word in attributes:\n",
    "            attribute_indices[word].append(i)\n",
    "\n",
    "    # Find pairs within the given window\n",
    "    attribute_pairs = set()\n",
    "    attribute_list = list(attribute_indices.keys())\n",
    "    for idx1, attribute1 in enumerate(attribute_list):\n",
    "        indices1 = attribute_indices[attribute1]\n",
    "        for idx2 in range(idx1 + 1, len(attribute_list)):\n",
    "            attribute2 = attribute_list[idx2]\n",
    "            indices2 = attribute_indices[attribute2]\n",
    "            for i1 in indices1:\n",
    "                for i2 in indices2:\n",
    "                    if abs(i1 - i2) - 1 <= window:\n",
    "                        pair = tuple(sorted((attribute1, attribute2)))\n",
    "                        attribute_pairs.add(pair)\n",
    "    return attribute_pairs\n",
    "\n",
    "# Function to calculate word frequencies and word pair co-occurrences\n",
    "def calculate_frequencies(df, input_attributes, window=50):\n",
    "    word_frequency = defaultdict(int)\n",
    "    word_pair_frequency = defaultdict(int)\n",
    "\n",
    "    # Loop through each post and count word occurrences\n",
    "    for index, row in df.iterrows():\n",
    "        message = row['product_review']\n",
    "        words_in_message = set(clean_text(message))\n",
    "        attributes_in_message = words_in_message.intersection(input_attributes)\n",
    "        \n",
    "        # Update word frequencies\n",
    "        for attribute in attributes_in_message:\n",
    "            word_frequency[attribute] += 1\n",
    "\n",
    "        # Update pair frequencies\n",
    "        attribute_pairs = find_attribute_pairs(message, input_attributes, window=window)\n",
    "        for attribute_pair in attribute_pairs:\n",
    "            if attribute_pair[0] in attributes_in_message and attribute_pair[1] in attributes_in_message:\n",
    "                word_pair_frequency[attribute_pair] += 1\n",
    "\n",
    "    return word_frequency, word_pair_frequency\n",
    "\n",
    "\n",
    "# Function to calculate lift\n",
    "def calculate_lift(word_frequency, word_pair_frequency, total_posts):\n",
    "    lift_values = []\n",
    "\n",
    "    for (attribute1, attribute2), pair_count in word_pair_frequency.items():\n",
    "        p_attribute1 = word_frequency[attribute1] / total_posts\n",
    "        p_attribute2 = word_frequency[attribute2] / total_posts\n",
    "        p_both = pair_count / total_posts\n",
    "\n",
    "        if p_attribute1 * p_attribute2 > 0:\n",
    "            lift = p_both / (p_attribute1 * p_attribute2)\n",
    "            lift_values.append({\n",
    "                'Attribute 1': attribute1,\n",
    "                'Attribute 2': attribute2,\n",
    "                'Lift': lift\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(lift_values)\n",
    "\n",
    "# Main function to process data and compute lift ratios\n",
    "def main(df, top_10_brands_list, window=50):\n",
    "    # Step 1: Calculate word and word pair frequencies\n",
    "    total_posts = len(df)\n",
    "    word_frequency, word_pair_frequency = calculate_frequencies(df, input_attributes, window)\n",
    "    \n",
    "    # Step 2: Calculate lift values\n",
    "    lift_df = calculate_lift(word_frequency, word_pair_frequency, total_posts)\n",
    "    \n",
    "    # Step 3: Create lift matrix\n",
    "    lift_matrix = lift_df.pivot(index='Attribute 1', columns='Attribute 2', values='Lift')\n",
    "    \n",
    "    # Ensure all attributes are present in both axes\n",
    "    all_attributes = sorted(set(input_attributes))\n",
    "    lift_matrix = lift_matrix.reindex(index=all_attributes, columns=all_attributes)\n",
    "    \n",
    "    # Replace missing values with 0\n",
    "    lift_matrix = lift_matrix.fillna(0)\n",
    "    \n",
    "    # Convert DataFrame to object type to allow setting string values\n",
    "    lift_matrix = lift_matrix.astype(object)\n",
    "    \n",
    "    # Set the diagonal and lower triangle to '-'\n",
    "    for i in range(len(all_attributes)):\n",
    "        lift_matrix.iloc[i, i] = '-'  # Set diagonal to '-'\n",
    "        for j in range(i):\n",
    "            lift_matrix.iloc[i, j] = '-'  # Set lower triangle to '-'\n",
    "    \n",
    "    # Remove labels from being displayed\n",
    "    lift_matrix.index.name = None\n",
    "    lift_matrix.columns.name = None\n",
    "    \n",
    "    # Return both lift_matrix and lift_df\n",
    "    return lift_matrix, lift_df\n",
    "\n",
    "# Execute the main function and capture the lift matrix and lift DataFrame\n",
    "lift_matrix, lift_df = main(df, input_attributes, window=5000)\n",
    "\n",
    "#Filter the matrix to include only high associations\n",
    "filtered_lift_df = lift_df[(lift_df['Lift'] > 2) & (lift_df['Lift'] <= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c579d59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Lift Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(earthy, sour, citrus)</td>\n",
       "      <td>10.650483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(hoppy, peppery, lingering)</td>\n",
       "      <td>10.245056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(earthy, tart, citrus)</td>\n",
       "      <td>10.046699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Attributes   Lift Sum\n",
       "0       (earthy, sour, citrus)  10.650483\n",
       "1  (hoppy, peppery, lingering)  10.245056\n",
       "2       (earthy, tart, citrus)  10.046699"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to select three attributes that have the highest lifts among all trio combinations\n",
    "def find_top_trios(filtered_lift_df, top_n=1):\n",
    "    \n",
    "    trio_lift_sums = defaultdict(float)\n",
    "    \n",
    "    # Create a set of all unique attributes involved in the filtered lift pairs\n",
    "    unique_attributes = set(filtered_lift_df['Attribute 1']).union(set(filtered_lift_df['Attribute 2']))\n",
    "    \n",
    "    # Generate all possible combinations of three attributes\n",
    "    for trio in combinations(unique_attributes, 3):\n",
    "        a1, a2, a3 = sorted(trio)\n",
    "        \n",
    "        # Get the lift values for each pair in the trio\n",
    "        lift_a1_a2 = filtered_lift_df[(filtered_lift_df['Attribute 1'] == a1) & (filtered_lift_df['Attribute 2'] == a2)]['Lift']\n",
    "        lift_a1_a3 = filtered_lift_df[(filtered_lift_df['Attribute 1'] == a1) & (filtered_lift_df['Attribute 2'] == a3)]['Lift']\n",
    "        lift_a2_a3 = filtered_lift_df[(filtered_lift_df['Attribute 1'] == a2) & (filtered_lift_df['Attribute 2'] == a3)]['Lift']\n",
    "        \n",
    "        # Calculate the sum\n",
    "        if not lift_a1_a2.empty and not lift_a1_a3.empty and not lift_a2_a3.empty:\n",
    "            trio_lift_sums[trio] = lift_a1_a2.values[0] + lift_a1_a3.values[0] + lift_a2_a3.values[0]\n",
    "\n",
    "    # Sort the trios\n",
    "    sorted_trios = sorted(trio_lift_sums.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    top_trios = [{'Attributes': triad, 'Lift Sum': lift_sum} for triad, lift_sum in sorted_trios]\n",
    "    \n",
    "    return pd.DataFrame(top_trios)\n",
    "\n",
    "# Display the top 3 trios\n",
    "top_three_trios = find_top_trios(filtered_lift_df, top_n=3)\n",
    "top_three_trios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fde2f7",
   "metadata": {},
   "source": [
    "Based on our finding here, we will use earthy, citrus, and sour as the three attributes chosen by the customer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc66bc6-6461-46b7-a662-57633721f018",
   "metadata": {},
   "source": [
    "# Task C: Perform a similarity analysis using cosine similarity with the three attributes specified by the customer and the reviews\n",
    "\n",
    "**Note: Used the bag-of-words model as opposed to word embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74cfb185-3927-4cf6-962b-de07fd4292ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script should accept a file as input that has the product attributes and calculate similarity scores (0-1) \n",
    "    # between these attributes and each review\n",
    "# Output file should have three columns: product_name (will have a row for each review), product_review, \n",
    "    # and similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d690e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity between attributes and multiple reviews \n",
    "# based on cosine similarity code Dr. Barua posted\n",
    "def calculate_similarity(attributes, reviews):\n",
    "    # Combine the attributes into one string (bag of words)\n",
    "    attributes_combined = ' '.join(attributes)\n",
    "    \n",
    "    # Combine the reviews into a list (to be vectorized) and add attributes as the first document\n",
    "    documents = [attributes_combined] + list(reviews)  # First document is the attributes\n",
    "    \n",
    "    # Use CountVectorizer to convert text to bag-of-words representation\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    sparse_matrix = count_vectorizer.fit_transform(documents)  # Vectorize all documents\n",
    "    \n",
    "    # Convert sparse matrix to dense (using todense()) for normalization and cosine similarity calculation\n",
    "    doc_term_matrix = sparse_matrix.todense()  # Using todense() as in the reference code\n",
    "    \n",
    "    # Normalize the term-document matrix by dividing each count by the sum of counts in the document\n",
    "    doc_term_matrix_normalized = doc_term_matrix / doc_term_matrix.sum(axis=1)\n",
    "    \n",
    "    # Create a DataFrame from the normalized term-document matrix\n",
    "    df = pd.DataFrame(doc_term_matrix_normalized, columns=count_vectorizer.get_feature_names_out(), index=['attributes'] + [f'review_{i}' for i in range(len(reviews))])\n",
    "    \n",
    "    # Calculate cosine similarity between the first document (attributes) and each review\n",
    "    similarity_scores = cosine_similarity(df.iloc[0:1], df.iloc[1:]).flatten()  # Skip first row (attributes)\n",
    "    \n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb42153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute cosine similarity function and capture similarities for chosen attributes \n",
    "\n",
    "attributes = ['citrus', 'earthy', 'sour']  \n",
    "reviews = df['product_review']\n",
    "product_names = df['product_name'] \n",
    "\n",
    "# Calculate similarity for all reviews\n",
    "similarity_scores = calculate_similarity(attributes, reviews)\n",
    "\n",
    "# Create a new DataFrame with product_name, product_review, and similarity_score\n",
    "output_df = pd.DataFrame({\n",
    "    'product_name': product_names,\n",
    "    'product_review': reviews,\n",
    "    'similarity_score': similarity_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91160175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_review</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3 Fonteinen J &amp; J Oude Geuze Blauw</td>\n",
       "      <td>(Bottle 75 cl) Courtesy of yespr. Pours a clou...</td>\n",
       "      <td>0.400320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>3 Fonteinen Oude Geuze 1998 (50th Anniversary)</td>\n",
       "      <td>Beer #10000! Bottle at Akkurat, Stockholm. Cle...</td>\n",
       "      <td>0.383598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>De Dolle Stille Nacht Reserva 2000</td>\n",
       "      <td>#1900, thanks to bu11zeye, cloudy color of gra...</td>\n",
       "      <td>0.361158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3 Fonteinen Oude Geuze 1998 (50th Anniversary)</td>\n",
       "      <td>Bottled @RBESG’05\\r\\n\\r\\nPale yellow, creamy w...</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3 Fonteinen Oude Geuze 1998 (50th Anniversary)</td>\n",
       "      <td>Big, big thanks Jason for opening this one up ...</td>\n",
       "      <td>0.348155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       product_name  \\\n",
       "64               3 Fonteinen J & J Oude Geuze Blauw   \n",
       "156  3 Fonteinen Oude Geuze 1998 (50th Anniversary)   \n",
       "814              De Dolle Stille Nacht Reserva 2000   \n",
       "107  3 Fonteinen Oude Geuze 1998 (50th Anniversary)   \n",
       "126  3 Fonteinen Oude Geuze 1998 (50th Anniversary)   \n",
       "\n",
       "                                        product_review  similarity_score  \n",
       "64   (Bottle 75 cl) Courtesy of yespr. Pours a clou...          0.400320  \n",
       "156  Beer #10000! Bottle at Akkurat, Stockholm. Cle...          0.383598  \n",
       "814  #1900, thanks to bu11zeye, cloudy color of gra...          0.361158  \n",
       "107  Bottled @RBESG’05\\r\\n\\r\\nPale yellow, creamy w...          0.353553  \n",
       "126  Big, big thanks Jason for opening this one up ...          0.348155  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort output_df by similarity_score in descending order (highest to lowest)\n",
    "output_df_sorted = output_df.sort_values(by='similarity_score', ascending=False)\n",
    "\n",
    "# Display the first few rows of the sorted DataFrame\n",
    "output_df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "245d40c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with similarity score > 0: 277\n"
     ]
    }
   ],
   "source": [
    "# Count rows where similarity_score is greater than 0\n",
    "rows_with_similarity = output_df[output_df['similarity_score'] > 0].shape[0]\n",
    "print(f\"Number of rows with similarity score > 0: {rows_with_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a6a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_df.to_csv('cos_similiarities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7413e-f53f-443e-92e9-dba26f32b7bd",
   "metadata": {},
   "source": [
    "# Task D: Perform a sentiment analysis for every review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ad331070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used ChatGPT to generate sentiment scores for each review\n",
    "\n",
    "with open('api_key.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "openai.api_key = config['api_key']\n",
    "\n",
    "def convert_int(s):\n",
    "    s = s.strip()\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        try:\n",
    "            float(s)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "def get_sentiment(review_text, rating):\n",
    "    non_int_count = 0\n",
    "    \n",
    "    while non_int_count < 2:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": f\"\"\"\n",
    "                    You are a sentiment analysis expert trained to evaluate beer reviews. Your task is to provide sentiment scores for each beer review on a scale from -100 (extremely negative) to 100 (extremely positive).\n",
    "                    - Use the rating (1-5) to detect sarcasm if the text contains clear cues.\n",
    "                    - Do not assume sarcasm solely due to mismatched sentiment and rating.\n",
    "                    - Only output the sentiment score as an integer. Only 1 sentiment score should be outputted, regardless of number of reviews given.\n",
    "                    Review: \"{review_text}\"\n",
    "                    Rating: {rating} out of 5\n",
    "                    Response Format: [sentiment value]\n",
    "                    \"\"\"\n",
    "                }\n",
    "            ],\n",
    "            temperature = 0\n",
    "        )\n",
    "        sentiment = completion.choices[0].message['content'].strip()\n",
    "        print(f\"Sentiment value received: '{sentiment}', Type: {type(sentiment)}\")\n",
    "        if convert_int(sentiment):\n",
    "            return sentiment\n",
    "        else:\n",
    "            non_int_count += 1\n",
    "            print(sentiment)\n",
    "        \n",
    "    raise ValueError(f\"Error: More than 2 consecutive non-integer sentiment values encountered for review: '{review_text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55b820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply the sentiment analysis function to the DataFrame\n",
    "# df['sentiment'] = df.apply(lambda row: get_sentiment(row['product_review'], row['rating']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e76c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV file\n",
    "#df.to_csv('sentiments.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f9441-6f1d-47e7-8e41-92f966812ac9",
   "metadata": {},
   "source": [
    "# Task E: Create an evaluation score for each beer that uses both similarity and sentiment scores and recommended three products to the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deea05a9-ec89-477f-8c63-9d2ddb4d582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      product_name  evaluation_score\n",
      "1   3 Fonteinen Oude Geuze 1998 (50th Anniversary)          0.085702\n",
      "0               3 Fonteinen J & J Oude Geuze Blauw          0.078048\n",
      "16                 Russian River Pliny the Younger          0.046181\n"
     ]
    }
   ],
   "source": [
    "# Add sentiment and similarity scores for the three products recommended.\n",
    "# Create a df with product_name, product_review, similarity, sentiment, evaluation\n",
    "# Use all similarity rows\n",
    "# Recommend top 3 products based on evaluation\n",
    "\n",
    "df = pd.read_csv('sentiments.csv')\n",
    "\n",
    "# Convert sentiment to numeric\n",
    "df['sentiment'] = pd.to_numeric(df['sentiment'], errors='coerce')\n",
    "\n",
    "# Normalize sentiment scores from -100 to 100 to -1 to 1\n",
    "df['sentiment'] = df['sentiment'] / 100\n",
    "\n",
    "df_combined = pd.merge(df, output_df[['product_name', 'product_review', 'similarity_score']], \n",
    "                       on=['product_name', 'product_review'], how='inner')\n",
    "\n",
    "# Calculate evaluation score\n",
    "df_combined['evaluation_score'] = df_combined['similarity_score'] * df_combined['sentiment']\n",
    "\n",
    "# Group by product_name and calculate the mean evaluation score for each beer\n",
    "product_evaluation = df_combined.groupby('product_name')['evaluation_score'].mean().reset_index()\n",
    "\n",
    "# Rank products\n",
    "top_products = product_evaluation.sort_values(by='evaluation_score', ascending=False)\n",
    "\n",
    "# Recommend top 3\n",
    "top_3_products = top_products.head(3)\n",
    "print(top_3_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6827b0-c1bb-4c98-be2d-5bf977cbed31",
   "metadata": {},
   "source": [
    "# Task F: How would our recommendations change if we use word vectors instead of the standard bag-of-words cosine similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2d1f546-8639-4dad-96b7-b2d26c154a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the % of reviews that mention a preferred attribute\n",
    "    # For a recommended product, what % of its reviews mention an attribute specified by the customer\n",
    "# Differences between bag-of-words and word vector approaches\n",
    "# Bag of words, under certain conditions, will likely be better than word embeddings for recommender systems\n",
    "# Show rating, similarity scores, and sentiments for the products recommended in this task and the previous one\n",
    "\n",
    "# Here we calculate the similarity between the same docs using word vectors (spacy)\n",
    "\n",
    "# Load the spaCy medium-sized English model\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# Function to calculate cosine similarity between attributes and reviews using spaCy embeddings\n",
    "def word2vec_sim(attributes, reviews):\n",
    "    # Combine the attributes into one string\n",
    "    attributes_combined = ' '.join(attributes)\n",
    "    \n",
    "    # Create the spaCy doc for the attributes\n",
    "    attributes_doc = nlp(attributes_combined)\n",
    "    \n",
    "    similarity_scores = [attributes_doc.similarity(nlp(review)) for review in reviews]\n",
    "    \n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67166125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute cosine similarity function and capture similarities for chosen attributes \n",
    "\n",
    "attributes = ['citrus', 'earthy', 'sour']  \n",
    "reviews = df['product_review']\n",
    "product_names = df['product_name'] \n",
    "\n",
    "# Calculate similarity for all reviews\n",
    "similarity_scores = word2vec_sim(attributes, reviews)\n",
    "\n",
    "# Create a new DataFrame with product_name, product_review, and similarity_score\n",
    "spacy_output_df = pd.DataFrame({\n",
    "    'product_name': product_names,\n",
    "    'product_review': reviews,\n",
    "    'similarity_score': similarity_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75589950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_review</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>AleSmith Speedway Stout</td>\n",
       "      <td>Bottle a black colored beer with a beige head ...</td>\n",
       "      <td>0.885468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>AleSmith Speedway Stout - Barrel-Aged Vietname...</td>\n",
       "      <td>On tap dark vanilla wood coffee licorice good ...</td>\n",
       "      <td>0.859436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>Cigar City Hunahpu's Imperial Stout - Double B...</td>\n",
       "      <td>Smell is cinnamon dough. Taste is delicious ci...</td>\n",
       "      <td>0.811349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>De Dolle Stille Nacht Reserva 2000</td>\n",
       "      <td>Bottle at yesprs blindtasting.\\r\\nHazy orange ...</td>\n",
       "      <td>0.793151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>AleSmith Speedway Stout - Bourbon Barrel Aged</td>\n",
       "      <td>Excellent stout. Particularly great with a sli...</td>\n",
       "      <td>0.787181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>De Dolle Stille Nacht Reserva 2000</td>\n",
       "      <td>This was an outstanding beer.  I paid $22 doll...</td>\n",
       "      <td>0.295919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>Perennial Abraxas - Barrel-Aged</td>\n",
       "      <td>This is being rated because they lost one of m...</td>\n",
       "      <td>0.293853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>Three Floyds Dark Lord - Bourbon Vanilla Bean</td>\n",
       "      <td>Holy shit!!! I have no words..... \\r\\n \\r\\n\\r\\...</td>\n",
       "      <td>0.292597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>Russian River Pliny the Younger</td>\n",
       "      <td>I've had this twice now and, while it's very g...</td>\n",
       "      <td>0.287224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>Three Floyds Dark Lord - Bourbon Barrel Aged</td>\n",
       "      <td>Did not live upto the hype. Not bad but this c...</td>\n",
       "      <td>0.280265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           product_name  \\\n",
       "260                             AleSmith Speedway Stout   \n",
       "396   AleSmith Speedway Stout - Barrel-Aged Vietname...   \n",
       "770   Cigar City Hunahpu's Imperial Stout - Double B...   \n",
       "834                  De Dolle Stille Nacht Reserva 2000   \n",
       "404       AleSmith Speedway Stout - Bourbon Barrel Aged   \n",
       "...                                                 ...   \n",
       "818                  De Dolle Stille Nacht Reserva 2000   \n",
       "1559                    Perennial Abraxas - Barrel-Aged   \n",
       "1882      Three Floyds Dark Lord - Bourbon Vanilla Bean   \n",
       "1602                    Russian River Pliny the Younger   \n",
       "1733       Three Floyds Dark Lord - Bourbon Barrel Aged   \n",
       "\n",
       "                                         product_review  similarity_score  \n",
       "260   Bottle a black colored beer with a beige head ...          0.885468  \n",
       "396   On tap dark vanilla wood coffee licorice good ...          0.859436  \n",
       "770   Smell is cinnamon dough. Taste is delicious ci...          0.811349  \n",
       "834   Bottle at yesprs blindtasting.\\r\\nHazy orange ...          0.793151  \n",
       "404   Excellent stout. Particularly great with a sli...          0.787181  \n",
       "...                                                 ...               ...  \n",
       "818   This was an outstanding beer.  I paid $22 doll...          0.295919  \n",
       "1559  This is being rated because they lost one of m...          0.293853  \n",
       "1882  Holy shit!!! I have no words..... \\r\\n \\r\\n\\r\\...          0.292597  \n",
       "1602  I've had this twice now and, while it's very g...          0.287224  \n",
       "1733  Did not live upto the hype. Not bad but this c...          0.280265  \n",
       "\n",
       "[2200 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_output_df.sort_values('similarity_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "209c3e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         product_name  evaluation_score\n",
      "3   AleSmith Speedway Stout - Barrel-Aged Vietname...          0.486373\n",
      "7   Cigar City Hunahpu's Imperial Stout - Double B...          0.486363\n",
      "15                    Perennial Abraxas - Barrel-Aged          0.478197\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sentiments.csv')\n",
    "\n",
    "# Convert sentiment to numeric\n",
    "df['sentiment'] = pd.to_numeric(df['sentiment'], errors='coerce')\n",
    "\n",
    "# Normalize sentiment scores from -100 to 100 to -1 to 1\n",
    "df['sentiment'] = df['sentiment'] / 100\n",
    "\n",
    "df_combined = pd.merge(df, spacy_output_df[['product_name', 'product_review', 'similarity_score']], \n",
    "                       on=['product_name', 'product_review'], how='inner')\n",
    "\n",
    "# Calculate evaluation score\n",
    "df_combined['evaluation_score'] = df_combined['similarity_score'] * df_combined['sentiment']\n",
    "\n",
    "# Group by product_name and calculate the mean evaluation score for each beer\n",
    "product_evaluation = df_combined.groupby('product_name')['evaluation_score'].mean().reset_index()\n",
    "\n",
    "# Rank products\n",
    "top_products = product_evaluation.sort_values(by='evaluation_score', ascending=False)\n",
    "\n",
    "# Recommend top 3\n",
    "top_3_products = top_products.head(3)\n",
    "print(top_3_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "724e8c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>evaluation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AleSmith Speedway Stout - Barrel-Aged Vietname...</td>\n",
       "      <td>0.486373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cigar City Hunahpu's Imperial Stout - Double B...</td>\n",
       "      <td>0.486363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Perennial Abraxas - Barrel-Aged</td>\n",
       "      <td>0.478197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cigar City Hunahpu's Imperial Stout</td>\n",
       "      <td>0.470055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>La Face Cachée de la Pomme Neige Récolte d'Hiver</td>\n",
       "      <td>0.467695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Goose Island Bourbon County Stout - Proprietor...</td>\n",
       "      <td>0.461357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Toppling Goliath Mornin' Delight</td>\n",
       "      <td>0.460090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Goose Island Bourbon County Stout - Rare 2010</td>\n",
       "      <td>0.450922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bell's Black Note Stout</td>\n",
       "      <td>0.441823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Founders CBS (Canadian Breakfast Stout)</td>\n",
       "      <td>0.441781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Närke Kaggen Stormaktsporter</td>\n",
       "      <td>0.434953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AleSmith Speedway Stout - Bourbon Barrel Aged</td>\n",
       "      <td>0.432463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Fonteinen Oude Geuze 1998 (50th Anniversary)</td>\n",
       "      <td>0.431320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 Fonteinen J &amp; J Oude Geuze Blauw</td>\n",
       "      <td>0.423605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AleSmith Speedway Stout</td>\n",
       "      <td>0.421883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Three Floyds Dark Lord - Bourbon Vanilla Bean</td>\n",
       "      <td>0.414215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Trappistes Rochefort 10</td>\n",
       "      <td>0.410462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>De Dolle Stille Nacht Reserva 2000</td>\n",
       "      <td>0.408081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Founders KBS (Kentucky Breakfast Stout)</td>\n",
       "      <td>0.402546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Three Floyds Dark Lord - Bourbon Barrel Aged</td>\n",
       "      <td>0.390606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Russian River Pliny the Younger</td>\n",
       "      <td>0.388220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Westvleteren 12</td>\n",
       "      <td>0.386710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         product_name  evaluation_score\n",
       "3   AleSmith Speedway Stout - Barrel-Aged Vietname...          0.486373\n",
       "7   Cigar City Hunahpu's Imperial Stout - Double B...          0.486363\n",
       "15                    Perennial Abraxas - Barrel-Aged          0.478197\n",
       "6                 Cigar City Hunahpu's Imperial Stout          0.470055\n",
       "13   La Face Cachée de la Pomme Neige Récolte d'Hiver          0.467695\n",
       "11  Goose Island Bourbon County Stout - Proprietor...          0.461357\n",
       "19                   Toppling Goliath Mornin' Delight          0.460090\n",
       "12      Goose Island Bourbon County Stout - Rare 2010          0.450922\n",
       "5                             Bell's Black Note Stout          0.441823\n",
       "9             Founders CBS (Canadian Breakfast Stout)          0.441781\n",
       "14                       Närke Kaggen Stormaktsporter          0.434953\n",
       "4       AleSmith Speedway Stout - Bourbon Barrel Aged          0.432463\n",
       "1      3 Fonteinen Oude Geuze 1998 (50th Anniversary)          0.431320\n",
       "0                  3 Fonteinen J & J Oude Geuze Blauw          0.423605\n",
       "2                             AleSmith Speedway Stout          0.421883\n",
       "18      Three Floyds Dark Lord - Bourbon Vanilla Bean          0.414215\n",
       "20                            Trappistes Rochefort 10          0.410462\n",
       "8                  De Dolle Stille Nacht Reserva 2000          0.408081\n",
       "10            Founders KBS (Kentucky Breakfast Stout)          0.402546\n",
       "17       Three Floyds Dark Lord - Bourbon Barrel Aged          0.390606\n",
       "16                    Russian River Pliny the Younger          0.388220\n",
       "21                                    Westvleteren 12          0.386710"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca59e7-de2f-44a7-b1b1-e06e49cf4825",
   "metadata": {},
   "source": [
    "# Task G: How would our recommendations differ if we ignored the similarity and feature sentiment scores and just chose the 3 highest rated products fro the entire data set? Would these products meet the requirements of the user looking for recommendations? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f970bf9-6998-4c23-9782-981fddd880bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Justify with analysis - use similarity and sentiment scores as well as overall ratings to answer this questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2235908-ff03-4ec7-92f6-1e41b6e0c26d",
   "metadata": {},
   "source": [
    "# Task H: From 10 beers in the data, choose 1, and find the most similar beer among the remaining 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "981a47ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Beer: Three Floyds Dark Lord - Bourbon Barrel Aged\n",
      "Remaining Beers: [\"Cigar City Hunahpu's Imperial Stout\", 'Founders KBS (Kentucky Breakfast Stout)', 'Three Floyds Dark Lord - Bourbon Vanilla Bean', \"Cigar City Hunahpu's Imperial Stout - Double Barrel Aged\", 'AleSmith Speedway Stout - Bourbon Barrel Aged', 'Trappistes Rochefort 10', 'AleSmith Speedway Stout - Barrel-Aged Vietnamese Coffee', \"Bell's Black Note Stout\", 'Goose Island Bourbon County Stout - Rare 2010']\n"
     ]
    }
   ],
   "source": [
    "# Select 10 Beers from the Dataset\n",
    "unique_beers = df['product_name'].unique()\n",
    "selected_beers = random.sample(list(unique_beers), 10)\n",
    "\n",
    "# Choose one beer as the target beer\n",
    "chosen_beer = selected_beers[0]\n",
    "print(f\"Chosen Beer: {chosen_beer}\")\n",
    "\n",
    "# Remaining beers to compare with\n",
    "remaining_beers = selected_beers[1:]\n",
    "print(f\"Remaining Beers: {remaining_beers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1208bd23",
   "metadata": {},
   "source": [
    "We begin by randomly selecting ten unique beers from the dataset. One beer is designated as the target beer, and the remaining nine beers constitute the comparison group. This selection ensures a diverse set of beers for meaningful comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0b992ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Mentioned Attributes in Each Review\n",
    "# We already have the list of top 25 attributes from Task B\n",
    "# Ensure attributes are in lowercase\n",
    "attributes = [attr.lower() for attr in top_25_attributes_list]\n",
    "\n",
    "# Function to identify attributes in a review\n",
    "def get_attributes_in_review(review, attributes):\n",
    "    review_words = set(re.findall(r'\\b\\w+\\b', review.lower()))\n",
    "    mentioned_attributes = review_words.intersection(attributes)\n",
    "    return mentioned_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cadfc2f",
   "metadata": {},
   "source": [
    "Using the top 25 attributes identified in earlier analysis (such as \"hoppy,\" \"fruity,\" \"bitter,\" etc.), we standardize these attributes by converting them to lowercase to maintain consistency during text matching.\n",
    "\n",
    "For each review associated with the selected beers, we extract the mentioned attributes. This involves parsing each review to identify words that match our list of attributes. By doing so, we capture the specific aspects of the beers that reviewers have commented on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8854b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Average Sentiment per Attribute per Beer\n",
    "beer_attribute_sentiments = {beer: {attr: [] for attr in attributes} for beer in selected_beers}\n",
    "\n",
    "# Iterate over each beer and its reviews\n",
    "for beer in selected_beers:\n",
    "    beer_reviews = df[df['product_name'] == beer]\n",
    "    for index, row in beer_reviews.iterrows():\n",
    "        review = row['product_review']\n",
    "        sentiment = row['sentiment']\n",
    "        mentioned_attrs = get_attributes_in_review(review, attributes)\n",
    "        for attr in mentioned_attrs:\n",
    "            beer_attribute_sentiments[beer][attr].append(sentiment)\n",
    "\n",
    "# Calculate average sentiment per attribute per beer\n",
    "beer_feature_vectors = {}\n",
    "for beer, attr_sentiments in beer_attribute_sentiments.items():\n",
    "    feature_vector = []\n",
    "    for attr in attributes:\n",
    "        sentiments = attr_sentiments[attr]\n",
    "        if sentiments:\n",
    "            avg_sentiment = sum(sentiments) / len(sentiments)\n",
    "        else:\n",
    "            avg_sentiment = 0  # Assign 0 if the attribute is not mentioned\n",
    "        feature_vector.append(avg_sentiment)\n",
    "    beer_feature_vectors[beer] = feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a126d",
   "metadata": {},
   "source": [
    "Each review in the dataset has an associated sentiment score, reflecting the overall positive or negative tone of the review. For every attribute mentioned in a review, we associate the sentiment score of that review with the attribute. This means that if a review mentions \"hoppy\" and has a positive sentiment score, \"hoppy\" will inherit that positive sentiment in the context of that beer.\n",
    "\n",
    "We aggregate the sentiment scores for each attribute across all reviews of a beer. By calculating the average sentiment score for each attribute, we create a profile that reflects how customers generally feel about each attribute of the beer. Attributes not mentioned in any reviews for a beer are assigned a neutral sentiment score of zero to indicate no available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bd88062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Feature Vectors for Each Beer\n",
    "feature_df = pd.DataFrame.from_dict(beer_feature_vectors, orient='index', columns=attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e05b4",
   "metadata": {},
   "source": [
    "With the average sentiment scores, we constructed a feature vector for each beer. This vector is a numerical representation where each dimension corresponds to one of the top attributes, and the value is the average sentiment score for that attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5caf99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Cosine Similarity Between Beers\n",
    "# Extract the feature vector for the chosen beer\n",
    "chosen_vector = feature_df.loc[chosen_beer].values.reshape(1, -1)\n",
    "\n",
    "# Check if the chosen_vector contains NaN values\n",
    "if np.isnan(chosen_vector).any():\n",
    "    chosen_vector = np.nan_to_num(chosen_vector)\n",
    "\n",
    "# Compute cosine similarity between the chosen beer and the remaining beers\n",
    "similarities = {}\n",
    "for beer in remaining_beers:\n",
    "    beer_vector = feature_df.loc[beer].values.reshape(1, -1)\n",
    "    \n",
    "    # Check if the beer_vector contains NaN values\n",
    "    if np.isnan(beer_vector).any():\n",
    "        beer_vector = np.nan_to_num(beer_vector)\n",
    "    \n",
    "    # Handle case where both vectors are zero vectors\n",
    "    if np.linalg.norm(chosen_vector) == 0 or np.linalg.norm(beer_vector) == 0:\n",
    "        sim_score = 0.0  # Assign similarity score of 0 if either vector is zero\n",
    "    else:\n",
    "        sim_score = cosine_similarity(chosen_vector, beer_vector)[0][0]\n",
    "    similarities[beer] = sim_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa4936",
   "metadata": {},
   "source": [
    "To quantify the similarity between beers, we compute the cosine similarity between the feature vector of the chosen beer and those of the other beers.\n",
    "\n",
    "By comparing the cosine similarity scores, we identify the beer with the highest similarity to the chosen beer. This beer is considered the most similar because it shares the most similar sentiment profile across the key attributes identified from customer reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "11817266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar beer to 'Three Floyds Dark Lord - Bourbon Barrel Aged' is 'Goose Island Bourbon County Stout - Rare 2010' with a similarity score of 0.8983.\n"
     ]
    }
   ],
   "source": [
    "# Identify the Most Similar Beer to the Chosen Beer\n",
    "# Find the beer with the highest similarity score\n",
    "most_similar_beer = max(similarities, key=similarities.get)\n",
    "highest_similarity_score = similarities[most_similar_beer]\n",
    "\n",
    "print(f\"The most similar beer to '{chosen_beer}' is '{most_similar_beer}' with a similarity score of {highest_similarity_score:.4f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
